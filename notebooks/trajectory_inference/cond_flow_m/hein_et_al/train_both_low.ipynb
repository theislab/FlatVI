{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1a9a81f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pytorch_lightning as pl\n",
    "import seml\n",
    "import numpy as np\n",
    "import torch\n",
    "from sacred import SETTINGS, Experiment\n",
    "from functools import partial\n",
    "\n",
    "import pandas as pd\n",
    "import anndata\n",
    "\n",
    "import scanpy as sc\n",
    "import scvelo as scv\n",
    "import cellrank as cr\n",
    "\n",
    "from PerturbSeq_CMV.datamodules.distribution_datamodule import TrajectoryDataModule\n",
    "from PerturbSeq_CMV.models.cfm_module import CFMLitModule\n",
    "from PerturbSeq_CMV.models.components.augmentation import AugmentationModule\n",
    "from PerturbSeq_CMV.models.components.simple_mlp import VelocityNet\n",
    "\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import yaml\n",
    "\n",
    "import sys \n",
    "sys.path.insert(0, \"../../../\" )\n",
    "from paths import EXPERIMENT_FOLDER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da295434",
   "metadata": {},
   "source": [
    "## Util functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a35e9128",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_velocity_to_adata(adata, model):\n",
    "    # Put model in evaluation mode\n",
    "    model.eval()\n",
    "    velocities = []\n",
    "    with torch.no_grad():\n",
    "        for i, x in enumerate(adata.X.A):\n",
    "            t = torch.tensor(adata.obs.experimental_time[i]).view(1, -1).float()\n",
    "            x = torch.from_numpy(x).to(model.device).view(1, -1).float()\n",
    "            dx_dt = model(t,x)\n",
    "            velocities.append(dx_dt.cpu().numpy())\n",
    "    velocities = np.concatenate(velocities, axis=0)\n",
    "\n",
    "    adata.layers[\"velocity\"] = velocities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e037b8b4",
   "metadata": {},
   "source": [
    "## Run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d124bb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/nfs/homedirs/pala/PerturbSeq_CMV/configs/datasets_standard_run/unperturbed_time_course_low.yaml\", \"r\") as stream:\n",
    "    hparams = yaml.safe_load(stream)[\"fixed\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6d541a",
   "metadata": {},
   "source": [
    "Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0e57120",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Global seed set to 42\n",
      "/nfs/homedirs/pala/miniconda3/envs/PerturbSeq_CMV/lib/python3.9/site-packages/anndata/_core/anndata.py:117: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    }
   ],
   "source": [
    "task_name = hparams[\"training.training\"][\"task_name\"]\n",
    "        \n",
    "# Fix seed for reproducibility\n",
    "torch.manual_seed(hparams[\"training.training\"][\"seed\"])      \n",
    "if hparams[\"training.training\"][\"seed\"]: \n",
    "    pl.seed_everything(hparams[\"training.training\"][\"seed\"], workers=True)\n",
    "\n",
    "# Initialize folder \n",
    "current_experiment_dir = EXPERIMENT_FOLDER / task_name\n",
    "current_experiment_dir.mkdir(parents=True, exist_ok=True) \n",
    "    \n",
    "\n",
    "# Initialize datamodule\n",
    "datamodule = TrajectoryDataModule(**hparams[\"datamodule.datamodule\"])\n",
    "    \n",
    "\n",
    "# Initialize augmentations\n",
    "augmentations = AugmentationModule(**hparams[\"augmentations.augmentations\"])\n",
    "         \n",
    "\n",
    "# Neural network \n",
    "net = partial(VelocityNet, **hparams[\"net.net\"])   \n",
    "\n",
    "\n",
    "# Initialize the model \n",
    "model = CFMLitModule(\n",
    "                    net=net,\n",
    "                    datamodule=datamodule,\n",
    "                    augmentations= augmentations, \n",
    "                    **hparams[\"model.model\"]\n",
    "                    ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07be0abb",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab8ef402",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mallepalma\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/nfs/homedirs/pala/PerturbSeq_CMV/project_folder/experiments/unperturbed_time_course_low/wandb/run-20230503_170436-ahvjf98q</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/allepalma/PerturbSeq_CMV/runs/ahvjf98q' target=\"_blank\">sunny-serenity-85</a></strong> to <a href='https://wandb.ai/allepalma/PerturbSeq_CMV' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/allepalma/PerturbSeq_CMV' target=\"_blank\">https://wandb.ai/allepalma/PerturbSeq_CMV</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/allepalma/PerturbSeq_CMV/runs/ahvjf98q' target=\"_blank\">https://wandb.ai/allepalma/PerturbSeq_CMV/runs/ahvjf98q</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/homedirs/pala/miniconda3/envs/PerturbSeq_CMV/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/homedirs/pala/miniconda3/envs/PerturbSeq_CMV/li ...\n",
      "  rank_zero_warn(\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/nfs/homedirs/pala/miniconda3/envs/PerturbSeq_CMV/lib/python3.9/site-packages/lightning_fabric/plugins/environments/slurm.py:165: PossibleUserWarning: The `srun` command is available on your system but is not used. HINT: If your intention is to run Lightning on SLURM, prepend your python command with `srun` like so: srun python /nfs/homedirs/pala/miniconda3/envs/PerturbSeq_CMV/li ...\n",
      "  rank_zero_warn(\n",
      "/nfs/homedirs/pala/miniconda3/envs/PerturbSeq_CMV/lib/python3.9/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:612: UserWarning: Checkpoint directory /nfs/students/pala/PerturbSeq_CMV/experiments/unperturbed_time_course_low/checkpoints exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type                 | Params\n",
      "-----------------------------------------------------------\n",
      "0 | net               | VelocityNet          | 471 K \n",
      "1 | augmentations     | AugmentationModule   | 0     \n",
      "2 | val_augmentations | AugmentationModule   | 0     \n",
      "3 | aug_net           | AugmentedVectorField | 471 K \n",
      "4 | val_aug_net       | AugmentedVectorField | 471 K \n",
      "5 | node              | NeuralODE            | 471 K \n",
      "6 | aug_node          | Sequential           | 471 K \n",
      "7 | val_aug_node      | Sequential           | 471 K \n",
      "8 | criterion         | MSELoss              | 0     \n",
      "-----------------------------------------------------------\n",
      "471 K     Trainable params\n",
      "0         Non-trainable params\n",
      "471 K     Total params\n",
      "1.885     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e38ab41b25624ee1a7a65b73eb26e513",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebd10f2e6be745fa9b97a55bf4509d18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3072, 3588])\n",
      "tensor([0.0000, 0.0100, 0.0200, 0.0300, 0.0400, 0.0500, 0.0600, 0.0700, 0.0800,\n",
      "        0.0900, 0.1000, 0.1100, 0.1200, 0.1300, 0.1400, 0.1500, 0.1600, 0.1700,\n",
      "        0.1800, 0.1900, 0.2000, 0.2100, 0.2200, 0.2300, 0.2400, 0.2500, 0.2600,\n",
      "        0.2700, 0.2800, 0.2900, 0.3000, 0.3100, 0.3200, 0.3300, 0.3400, 0.3500,\n",
      "        0.3600, 0.3700, 0.3800, 0.3900, 0.4000, 0.4100, 0.4200, 0.4300, 0.4400,\n",
      "        0.4500, 0.4600, 0.4700, 0.4800, 0.4900, 0.5000, 0.5100, 0.5200, 0.5300,\n",
      "        0.5400, 0.5500, 0.5600, 0.5700, 0.5800, 0.5900, 0.6000, 0.6100, 0.6200,\n",
      "        0.6300, 0.6400, 0.6500, 0.6600, 0.6700, 0.6800, 0.6900, 0.7000, 0.7100,\n",
      "        0.7200, 0.7300, 0.7400, 0.7500, 0.7600, 0.7700, 0.7800, 0.7900, 0.8000,\n",
      "        0.8100, 0.8200, 0.8300, 0.8400, 0.8500, 0.8600, 0.8700, 0.8800, 0.8900,\n",
      "        0.9000, 0.9100, 0.9200, 0.9300, 0.9400, 0.9500, 0.9600, 0.9700, 0.9800,\n",
      "        0.9900, 1.0000])\n",
      "torch.Size([3072, 3588])\n",
      "tensor([0.0000, 0.0100, 0.0200, 0.0300, 0.0400, 0.0500, 0.0600, 0.0700, 0.0800,\n",
      "        0.0900, 0.1000, 0.1100, 0.1200, 0.1300, 0.1400, 0.1500, 0.1600, 0.1700,\n",
      "        0.1800, 0.1900, 0.2000, 0.2100, 0.2200, 0.2300, 0.2400, 0.2500, 0.2600,\n",
      "        0.2700, 0.2800, 0.2900, 0.3000, 0.3100, 0.3200, 0.3300, 0.3400, 0.3500,\n",
      "        0.3600, 0.3700, 0.3800, 0.3900, 0.4000, 0.4100, 0.4200, 0.4300, 0.4400,\n",
      "        0.4500, 0.4600, 0.4700, 0.4800, 0.4900, 0.5000, 0.5100, 0.5200, 0.5300,\n",
      "        0.5400, 0.5500, 0.5600, 0.5700, 0.5800, 0.5900, 0.6000, 0.6100, 0.6200,\n",
      "        0.6300, 0.6400, 0.6500, 0.6600, 0.6700, 0.6800, 0.6900, 0.7000, 0.7100,\n",
      "        0.7200, 0.7300, 0.7400, 0.7500, 0.7600, 0.7700, 0.7800, 0.7900, 0.8000,\n",
      "        0.8100, 0.8200, 0.8300, 0.8400, 0.8500, 0.8600, 0.8700, 0.8800, 0.8900,\n",
      "        0.9000, 0.9100, 0.9200, 0.9300, 0.9400, 0.9500, 0.9600, 0.9700, 0.9800,\n",
      "        0.9900, 1.0000])\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 4.15 GiB (GPU 0; 10.92 GiB total capacity; 9.01 GiB already allocated; 1.07 GiB free; 9.24 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 22\u001b[0m\n\u001b[1;32m     15\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(default_root_dir\u001b[38;5;241m=\u001b[39mcurrent_experiment_dir,\n\u001b[1;32m     16\u001b[0m                   callbacks\u001b[38;5;241m=\u001b[39m[model_ckpt_callbacks, early_stopping_callbacks], \n\u001b[1;32m     17\u001b[0m                   logger\u001b[38;5;241m=\u001b[39mlogger, \n\u001b[1;32m     18\u001b[0m                   \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhparams[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrainer.trainer\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# Fit the model \u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                  \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdatamodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_dataloader\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m train_metrics \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mcallback_metrics\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# Test model \u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/PerturbSeq_CMV/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:520\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    518\u001b[0m model \u001b[38;5;241m=\u001b[39m _maybe_unwrap_optimized(model)\n\u001b[1;32m    519\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m_lightning_module \u001b[38;5;241m=\u001b[39m model\n\u001b[0;32m--> 520\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    521\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/PerturbSeq_CMV/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 44\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/miniconda3/envs/PerturbSeq_CMV/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:559\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_connector\u001b[38;5;241m.\u001b[39mattach_data(\n\u001b[1;32m    550\u001b[0m     model, train_dataloaders\u001b[38;5;241m=\u001b[39mtrain_dataloaders, val_dataloaders\u001b[38;5;241m=\u001b[39mval_dataloaders, datamodule\u001b[38;5;241m=\u001b[39mdatamodule\n\u001b[1;32m    551\u001b[0m )\n\u001b[1;32m    553\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    554\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    555\u001b[0m     ckpt_path,\n\u001b[1;32m    556\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    557\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    558\u001b[0m )\n\u001b[0;32m--> 559\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    562\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/PerturbSeq_CMV/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:935\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    930\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    932\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    933\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    934\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 935\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    940\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/PerturbSeq_CMV/lib/python3.9/site-packages/pytorch_lightning/trainer/trainer.py:978\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_sanity_check()\n\u001b[1;32m    977\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m--> 978\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    979\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnexpected state \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/PerturbSeq_CMV/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:201\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    202\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/PerturbSeq_CMV/lib/python3.9/site-packages/pytorch_lightning/loops/fit_loop.py:354\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher\u001b[38;5;241m.\u001b[39msetup(combined_loader)\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_training_epoch\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 354\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/PerturbSeq_CMV/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py:134\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madvance(data_fetcher)\n\u001b[0;32m--> 134\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_advance_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/PerturbSeq_CMV/lib/python3.9/site-packages/pytorch_lightning/loops/training_epoch_loop.py:248\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.on_advance_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_check_val:\n\u001b[1;32m    247\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mvalidating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;66;03m# update plateau LR scheduler after metrics are logged\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/PerturbSeq_CMV/lib/python3.9/site-packages/pytorch_lightning/loops/utilities.py:177\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    176\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 177\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/PerturbSeq_CMV/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py:122\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_restarting \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_dataloader_outputs()\n\u001b[0;32m--> 122\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mon_run_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/PerturbSeq_CMV/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py:244\u001b[0m, in \u001b[0;36m_EvaluationLoop.on_run_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39m_logger_connector\u001b[38;5;241m.\u001b[39m_evaluation_epoch_end()\n\u001b[1;32m    243\u001b[0m \u001b[38;5;66;03m# hook\u001b[39;00m\n\u001b[0;32m--> 244\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_on_evaluation_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m logged_outputs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logged_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logged_outputs, []  \u001b[38;5;66;03m# free memory\u001b[39;00m\n\u001b[1;32m    247\u001b[0m \u001b[38;5;66;03m# include any logged outputs on epoch_end\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/PerturbSeq_CMV/lib/python3.9/site-packages/pytorch_lightning/loops/evaluation_loop.py:326\u001b[0m, in \u001b[0;36m_EvaluationLoop._on_evaluation_epoch_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    324\u001b[0m hook_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_test_epoch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mtesting \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_validation_epoch_end\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    325\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(trainer, hook_name)\n\u001b[0;32m--> 326\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhook_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m trainer\u001b[38;5;241m.\u001b[39m_logger_connector\u001b[38;5;241m.\u001b[39mon_epoch_end()\n",
      "File \u001b[0;32m~/miniconda3/envs/PerturbSeq_CMV/lib/python3.9/site-packages/pytorch_lightning/trainer/call.py:142\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    139\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m hook_name\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 142\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m    145\u001b[0m pl_module\u001b[38;5;241m.\u001b[39m_current_fx_name \u001b[38;5;241m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/PerturbSeq_CMV/PerturbSeq_CMV/models/cfm_module.py:211\u001b[0m, in \u001b[0;36mCFMLitModule.on_validation_epoch_end\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mon_validation_epoch_end\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval_epoch_end\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mval\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PerturbSeq_CMV/PerturbSeq_CMV/models/cfm_module.py:260\u001b[0m, in \u001b[0;36mCFMLitModule.eval_epoch_end\u001b[0;34m(self, prefix)\u001b[0m\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28mprint\u001b[39m(x_start\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m    259\u001b[0m \u001b[38;5;28mprint\u001b[39m(t_span)\n\u001b[0;32m--> 260\u001b[0m _, aug_traj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_aug_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_span\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Push forward observations \u001b[39;00m\n\u001b[1;32m    261\u001b[0m aug, traj \u001b[38;5;241m=\u001b[39m aug_traj[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :, :aug_dims], aug_traj[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, :, aug_dims:] \u001b[38;5;66;03m# Only pick last observations in the traj\u001b[39;00m\n\u001b[1;32m    262\u001b[0m trajs\u001b[38;5;241m.\u001b[39mappend(traj\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu())\n",
      "File \u001b[0;32m~/miniconda3/envs/PerturbSeq_CMV/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/PerturbSeq_CMV/PerturbSeq_CMV/models/components/augmentation.py:288\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, *input)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mvalues():\n\u001b[0;32m--> 288\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/envs/PerturbSeq_CMV/lib/python3.9/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1195\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/miniconda3/envs/PerturbSeq_CMV/lib/python3.9/site-packages/torchdyn/core/neuralde.py:93\u001b[0m, in \u001b[0;36mNeuralODE.forward\u001b[0;34m(self, x, t_span)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x:Tensor, t_span:Tensor\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     92\u001b[0m     x, t_span \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prep_integration(x, t_span)\n\u001b[0;32m---> 93\u001b[0m     t_eval, sol \u001b[38;5;241m=\u001b[39m  \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_span\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_t_eval: \u001b[38;5;28;01mreturn\u001b[39;00m t_eval, sol\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m sol\n",
      "File \u001b[0;32m~/miniconda3/envs/PerturbSeq_CMV/lib/python3.9/site-packages/torchdyn/core/problems.py:79\u001b[0m, in \u001b[0;36mODEProblem.forward\u001b[0;34m(self, x, t_span)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x:Tensor, t_span:Tensor):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFor safety redirects to intended method `odeint`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43modeint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_span\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/PerturbSeq_CMV/lib/python3.9/site-packages/torchdyn/core/problems.py:73\u001b[0m, in \u001b[0;36mODEProblem.odeint\u001b[0;34m(self, x, t_span)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prep_odeint()\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msensalg \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mautograd\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43modeint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_span\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43matol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrtol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mautograd_function(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvf_params, x, t_span)\n",
      "File \u001b[0;32m~/miniconda3/envs/PerturbSeq_CMV/lib/python3.9/site-packages/torchdyn/numerics/odeint.py:83\u001b[0m, in \u001b[0;36modeint\u001b[0;34m(f, x, t_span, solver, atol, rtol, t_stops, verbose, interpolator, return_all_eval, seminorm)\u001b[0m\n\u001b[1;32m     81\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m atol \u001b[38;5;241m!=\u001b[39m odeint\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__defaults__\u001b[39m[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m rtol \u001b[38;5;241m!=\u001b[39m odeint\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__defaults__\u001b[39m[\u001b[38;5;241m1\u001b[39m]:\n\u001b[1;32m     82\u001b[0m \t\twarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSetting tolerances has no effect on fixed-step methods\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 83\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_fixed_odeint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_span\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolver\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m stepping_class \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madaptive\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     85\u001b[0m \tt \u001b[38;5;241m=\u001b[39m t_span[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/PerturbSeq_CMV/lib/python3.9/site-packages/torchdyn/numerics/odeint.py:417\u001b[0m, in \u001b[0;36m_fixed_odeint\u001b[0;34m(f, x, t_span, solver)\u001b[0m\n\u001b[1;32m    415\u001b[0m \t\u001b[38;5;28;01mif\u001b[39;00m steps \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(t_span) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m: dt \u001b[38;5;241m=\u001b[39m t_span[steps\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m t\n\u001b[1;32m    416\u001b[0m \tsteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 417\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m t_span, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43msol\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 4.15 GiB (GPU 0; 10.92 GiB total capacity; 9.01 GiB already allocated; 1.07 GiB free; 9.24 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "# Initialize callbacks \n",
    "model_ckpt_callbacks = ModelCheckpoint(dirpath=current_experiment_dir / \"checkpoints\", \n",
    "                                        **hparams[\"model_checkpoint.model_checkpoint\"])\n",
    "\n",
    "\n",
    "# Initialize callbacks \n",
    "early_stopping_callbacks = EarlyStopping(**hparams[\"early_stopping.early_stopping\"])\n",
    "        \n",
    "\n",
    "# Initialize logger \n",
    "logger = WandbLogger(save_dir=current_experiment_dir, \n",
    "                     **hparams[\"logger.logger\"]) \n",
    "\n",
    "# Initialize the lightning trainer \n",
    "trainer = Trainer(default_root_dir=current_experiment_dir,\n",
    "                  callbacks=[model_ckpt_callbacks, early_stopping_callbacks], \n",
    "                  logger=logger, \n",
    "                  **hparams[\"trainer.trainer\"])\n",
    "        \n",
    "\n",
    "# Fit the model \n",
    "trainer.fit(model=model, \n",
    "                  train_dataloaders=datamodule.train_dataloader(),\n",
    "                  val_dataloaders=datamodule.val_dataloader())\n",
    "train_metrics = trainer.callback_metrics\n",
    "\n",
    "# Test model \n",
    "ckpt_path = trainer.checkpoint_callback.best_model_path\n",
    "if ckpt_path == \"\":\n",
    "    ckpt_path = None\n",
    "trainer.test(model=model, datamodule=datamodule, ckpt_path=ckpt_path)\n",
    "test_metrics = trainer.callback_metrics\n",
    "\n",
    "# merge train and test metrics\n",
    "metric_dict = {**train_metrics, **test_metrics}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aec509f",
   "metadata": {},
   "source": [
    "## Anlyze vector field with CellRank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9821f6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/nfs/homedirs/pala/miniconda3/envs/PerturbSeq_CMV/lib/python3.9/site-packages/anndata/_core/anndata.py:117: ImplicitModificationWarning: Transforming to str index.\n",
      "  warnings.warn(\"Transforming to str index.\", ImplicitModificationWarning)\n"
     ]
    }
   ],
   "source": [
    "adata = sc.read_h5ad(\"/nfs/homedirs/pala/PerturbSeq_CMV/project_folder/data/processed/unperturbed_time_course_low.h5ad\")\n",
    "adata = adata[:, adata.var.highly_variable]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee7adab",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_velocity_to_adata(adata, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1d0033",
   "metadata": {},
   "outputs": [],
   "source": [
    "vk = cr.kernels.VelocityKernel(adata,\n",
    "                          xkey=\"X\", \n",
    "                        vkey=\"velocity\").compute_transition_matrix()\n",
    "\n",
    "ck = cr.kernels.ConnectivityKernel(adata).compute_transition_matrix()\n",
    "\n",
    "\n",
    "combined_kernel = 0.8 * vk + 0.2 * ck\n",
    "\n",
    "combined_kernel.compute_transition_matrix().compute_projection(basis=\"umap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9650519",
   "metadata": {},
   "outputs": [],
   "source": [
    "scv.pl.velocity_embedding_stream(adata, vkey=\"T_fwd\", basis=\"umap\", color=\"cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52029962",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpcc = cr.estimators.GPCCA(combined_kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3121dd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpcc.compute_schur(n_components=20)\n",
    "gpcc.plot_spectrum(real_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a4b8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpcc.compute_macrostates(n_states=4, cluster_key=\"cluster\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7771b9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpcc.plot_macrostates(\n",
    "    discrete=True, size=100, basis=\"umap\", title=\"Macrostates - labeled\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06d690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpcc.set_terminal_states_from_macrostates(names=[\"infected_6\", \"infected_abortive\", \"bystander\", \n",
    "                                                        \"naive\"])\n",
    "gpcc.compute_absorption_probabilities()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a402fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpcc.plot_absorption_probabilities(same_plot=False, size=50, basis=\"umap\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4f165a",
   "metadata": {},
   "source": [
    "## Plot trajectories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e1f0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2time = {0.0: 0.0,\n",
    "            1.0: 6.0, \n",
    "            2.0: 20.0, \n",
    "            3.0: 28.0, \n",
    "            4.0: 48.0, \n",
    "            5.0: 72.0, \n",
    "            6.0: 96.0, \n",
    "            7.0: 120.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab4b858",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model \n",
    "ckpt_path = \"/nfs/homedirs/pala/PerturbSeq_CMV/project_folder/experiments/unperturbed_time_course_low/checkpoints/last-v7.ckpt\"\n",
    "\n",
    "\n",
    "model.load_state_dict(torch.load(ckpt_path)[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "831b820b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trajectories = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5decf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_loader = datamodule.train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e3321c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect trajectories \n",
    "t_interp = torch.linspace(0, 1, 1).unsqueeze(0)\n",
    "t_ext = torch.arange(8).unsqueeze(1)\n",
    "t_int = (t_interp+t_ext).ravel()\n",
    "obs = {\"experimental_time\": []}\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in cell_loader:\n",
    "        batch = model.unpack_batch(batch)\n",
    "        x_start = batch[:,0,:]\n",
    "        times = [idx2time[idx] for idx in range(8)]\n",
    "        obs[\"experimental_time\"].append(torch.tensor(times).unsqueeze(1).repeat(1, batch.shape[0]))\n",
    "        _, traj = model.val_aug_node(x_start, t_int)\n",
    "        trajectories.append(traj[:,:,3:].clamp(min=0).cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d9586c",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_cat = torch.cat(trajectories, dim=1)\n",
    "obs[\"experimental_time\"] = torch.cat(obs[\"experimental_time\"], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ea8567",
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_ravel = traj_cat.view(-1, traj_cat.shape[2])\n",
    "obs[\"experimental_time\"] = obs[\"experimental_time\"].view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "373ee09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_extrap = anndata.AnnData(X=traj_ravel.numpy(), \n",
    "                              obs=pd.DataFrame(obs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9febe6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(adata_extrap, svd_solver=\"arpack\")\n",
    "sc.pp.neighbors(adata_extrap, n_pcs=30)\n",
    "sc.tl.umap(adata_extrap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599f2274",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata_extrap, color=\"experimental_time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1247e118",
   "metadata": {},
   "source": [
    "## Put together real and generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab063d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_concat = np.concatenate([adata.X.A, adata_extrap.X], axis=0)\n",
    "obs_concat = pd.DataFrame((pd.concat([adata.obs.experimental_time, adata_extrap.obs.experimental_time])))\n",
    "obs_concat[\"true_generated\"] = np.array([1 for _ in range(adata.n_obs)] + \n",
    "                                        [0 for _ in range(adata_extrap.n_obs)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99885948",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_joint = anndata.AnnData(X=X_concat,\n",
    "                             obs=obs_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87fcbb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_joint.obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd9ea24",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(adata_joint, svd_solver=\"arpack\")\n",
    "sc.pp.neighbors(adata_joint, n_pcs=30)\n",
    "sc.tl.umap(adata_joint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75e7bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata_joint, color=[\"experimental_time\", \"true_generated\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e766f48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "d5240001f602d094a653e72667f1f126473feea48647f48d8a8ce2a6fb0c39cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
