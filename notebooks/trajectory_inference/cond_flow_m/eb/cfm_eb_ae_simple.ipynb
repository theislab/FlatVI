{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9a81f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pytorch_lightning as pl\n",
    "import seml\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "from sacred import SETTINGS, Experiment\n",
    "from functools import partial\n",
    "\n",
    "import scanpy as sc\n",
    "import scvelo as scv\n",
    "import cellrank as cr\n",
    "import pandas as pd\n",
    "\n",
    "from torchdyn.core import NeuralODE\n",
    "\n",
    "from scCFM.datamodules.sc_datamodule import scDataModule\n",
    "from scCFM.datamodules.time_sc_datamodule import TrajectoryDataModule\n",
    "from scCFM.models.base.vae import VAE, AE\n",
    "from scCFM.models.cfm.cfm_module import CFMLitModule\n",
    "from scCFM.models.cfm.components.simple_mlp import VelocityNet\n",
    " \n",
    "from conditional_flow_matching import *\n",
    "\n",
    "from torch.optim import AdamW\n",
    "\n",
    "import yaml\n",
    "\n",
    "import sys \n",
    "sys.path.insert(0, \"../../../\" )\n",
    "from paths import EXPERIMENT_FOLDER\n",
    "\n",
    "from conditional_flow_matching import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e037b8b4",
   "metadata": {},
   "source": [
    "## Import configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d124bb81",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/nfs/homedirs/pala/scCFM/configs/ae/eb/config.yaml\", \"r\") as stream:\n",
    "    hparams_ae = yaml.safe_load(stream)[\"fixed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ba8ce8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class torch_wrapper(torch.nn.Module):\n",
    "    \"\"\"Wraps model to torchdyn compatible format.\"\"\"\n",
    "\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "\n",
    "    def forward(self, t, x):\n",
    "        return self.model(torch.cat([x, t.repeat(x.shape[0])[:, None]], 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67f12d4",
   "metadata": {},
   "source": [
    "## Initialize and train/load autoencoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "ba5a587d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_ae = True\n",
    "pretrained_ckpt_ae = \"/nfs/students/pala/scCFM/experiments/ae/eb_vae/checkpoints/epoch_0033.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "1d5662d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = hparams_ae[\"training.training\"][\"task_name\"]\n",
    "        \n",
    "# Fix seed for reproducibility\n",
    "torch.manual_seed(hparams_ae[\"training.training\"][\"seed\"])      \n",
    "if hparams_ae[\"training.training\"][\"seed\"]: \n",
    "    pl.seed_everything(hparams_ae[\"training.training\"][\"seed\"], workers=True)\n",
    "\n",
    "# Initialize folder \n",
    "current_experiment_dir = EXPERIMENT_FOLDER / \"ae\" / task_name\n",
    "current_experiment_dir.mkdir(parents=True, exist_ok=True) \n",
    "    \n",
    "\n",
    "# Initialize datamodule\n",
    "datamodule = scDataModule(**hparams_ae[\"datamodule.datamodule\"])\n",
    "\n",
    "\n",
    "# Initialize the model \n",
    "ae_model = VAE(in_dim = datamodule.dim,\n",
    "            **hparams_ae[\"model.model\"]\n",
    "            ) \n",
    "        \n",
    "if not pretrained_ae:\n",
    "    # Initialize callbacks \n",
    "    model_ckpt_callbacks = ModelCheckpoint(dirpath=current_experiment_dir / \"checkpoints\", \n",
    "                                            **hparams_ae[\"model_checkpoint.model_checkpoint\"])\n",
    "\n",
    "\n",
    "    # Initialize callbacks \n",
    "    early_stopping_callbacks = EarlyStopping(**hparams_ae[\"early_stopping.early_stopping\"])\n",
    "\n",
    "\n",
    "    # Initialize logger \n",
    "    logger = WandbLogger(save_dir=current_experiment_dir / \"logs\", \n",
    "                         **hparams_ae[\"logger.logger\"]) \n",
    "\n",
    "\n",
    "    # Initialize the lightning trainer \n",
    "    trainer = Trainer(default_root_dir=current_experiment_dir,\n",
    "                      callbacks=[model_ckpt_callbacks, early_stopping_callbacks], \n",
    "                      logger=logger, \n",
    "                      **hparams_ae[\"trainer.trainer\"])\n",
    "\n",
    "\n",
    "    # # Fit the model \n",
    "    trainer.fit(model=ae_model, \n",
    "                      train_dataloaders=datamodule.train_dataloader(),\n",
    "                      val_dataloaders=datamodule.val_dataloader())\n",
    "    train_metrics = trainer.callback_metrics\n",
    "\n",
    "else:\n",
    "    ae_model.load_state_dict(torch.load(pretrained_ckpt_ae)[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1e843c8",
   "metadata": {},
   "source": [
    "**Analyze autoencoder latent space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "4833d7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "z_cells = []\n",
    "annot = []\n",
    "with torch.no_grad():\n",
    "    for batch in datamodule.train_dataloader():\n",
    "        annot.append(batch[\"cond\"])\n",
    "        mu = ae_model.encode(batch[\"X\"])[\"z\"]\n",
    "        z_cells.append(mu)\n",
    "\n",
    "z_cells= torch.cat(z_cells, dim=0)\n",
    "annot = pd.DataFrame(torch.cat(annot).numpy())\n",
    "annot.columns = [\"experimental_time\"]\n",
    "\n",
    "adata_latent = sc.AnnData(X=z_cells.cpu().numpy(), \n",
    "                  obs=annot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "4aecd43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(adata_latent)\n",
    "sc.pp.neighbors(adata_latent)\n",
    "sc.tl.umap(adata_latent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "789bf619",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata_latent, color=\"experimental_time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e3faf63",
   "metadata": {},
   "source": [
    "## Perform CFM training like in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "6f815b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, dim, out_dim=None, w=64, time_varying=False):\n",
    "        super().__init__()\n",
    "        self.time_varying = time_varying\n",
    "        if out_dim is None:\n",
    "            out_dim = dim\n",
    "        self.net = torch.nn.Sequential(\n",
    "            torch.nn.Linear(dim + (1 if time_varying else 0), w),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.Linear(w, w),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.Linear(w, w),\n",
    "            torch.nn.SELU(),\n",
    "            torch.nn.Linear(w, out_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f186ff62",
   "metadata": {},
   "source": [
    "First we standardize the coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "cfc31ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "times = sorted(adata_latent.obs[\"experimental_time\"].unique())\n",
    "n_times = len(times)\n",
    "# Standardize coordinates\n",
    "coords = adata_latent.X\n",
    "coords = (coords - coords.mean(axis=0)) / coords.std(axis=0)\n",
    "adata_latent.layers[\"X_standardized\"] = coords\n",
    "X = [\n",
    "    adata_latent.layers[\"X_standardized\"][adata_latent.obs[\"experimental_time\"] == t]\n",
    "    for t in times\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "73cabb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape of the time batches\n",
    "[i.shape for i in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "95c8fa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "batch_size = 256\n",
    "sigma = 0.1\n",
    "dim = 64\n",
    "model = MLP(dim=dim, time_varying=True, w=64).to(device)\n",
    "# score_model = MLP(dim=dim, time_varying=True, w=64)\n",
    "optimizer = torch.optim.Adam(model.parameters(), 1e-4)\n",
    "# FM = ConditionalFlowMatcher(sigma=sigma)\n",
    "FM = ExactOptimalTransportConditionalFlowMatcher(sigma=sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e850a10",
   "metadata": {},
   "source": [
    "Batch collecting function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "621db59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(FM, X, batch_size, n_times, return_noise=False):\n",
    "    \"\"\"Construct a batch with point sfrom each timepoint pair\"\"\"\n",
    "    ts = []\n",
    "    xts = []\n",
    "    uts = []\n",
    "    noises = []\n",
    "    for t_start in range(n_times - 1):\n",
    "        x0 = (\n",
    "            torch.from_numpy(X[t_start][np.random.randint(X[t_start].shape[0], size=batch_size)])\n",
    "            .float()\n",
    "            .to(device)\n",
    "        )\n",
    "        x1 = (\n",
    "            torch.from_numpy(\n",
    "                X[t_start + 1][np.random.randint(X[t_start + 1].shape[0], size=batch_size)]\n",
    "            )\n",
    "            .float()\n",
    "            .to(device)\n",
    "        )\n",
    "        if return_noise:\n",
    "            t, xt, ut, eps = FM.sample_location_and_conditional_flow(\n",
    "                x0, x1, return_noise=return_noise\n",
    "            )\n",
    "            noises.append(eps)\n",
    "        else:\n",
    "            t, xt, ut = FM.sample_location_and_conditional_flow(x0, x1, return_noise=return_noise)\n",
    "        ts.append(t + t_start)\n",
    "        xts.append(xt)\n",
    "        uts.append(ut)\n",
    "    t = torch.cat(ts)\n",
    "    xt = torch.cat(xts)\n",
    "    ut = torch.cat(uts)\n",
    "    if return_noise:\n",
    "        noises = torch.cat(noises)\n",
    "        return t, xt, ut, noises\n",
    "    return t, xt, ut"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f4ed07",
   "metadata": {},
   "source": [
    "Train OT cfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24bdd03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in tqdm(range(10000)):\n",
    "    optimizer.zero_grad()\n",
    "    t, xt, ut = get_batch(FM, X, batch_size, n_times)\n",
    "    vt = model(torch.cat([xt, t[:, None]], dim=-1))\n",
    "    loss = torch.mean((vt - ut) ** 2)\n",
    "    loss.backward()\n",
    "    if i % 20 == 0:\n",
    "        print(loss)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4cd840",
   "metadata": {},
   "source": [
    "**Check the streamplots**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453aaef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_velocity_to_adata(adata, model):\n",
    "    # Put model in evaluation mode\n",
    "    model.eval()\n",
    "    velocities = []\n",
    "    with torch.no_grad():\n",
    "        for i, x in enumerate(adata.X):\n",
    "            t = torch.tensor(adata.obs.experimental_time[i]).view(1, -1).float().cuda()\n",
    "            x = torch.from_numpy(x).view(1, -1).float().cuda()\n",
    "            dx_dt = model(torch.cat([x, t], dim=1))\n",
    "            velocities.append(dx_dt.cpu().numpy())\n",
    "    velocities = np.concatenate(velocities, axis=0)\n",
    "\n",
    "    adata.layers[\"velocity\"] = velocities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea6f423",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_velocity_to_adata(adata_latent, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeeac2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_latent.layers[\"X_latent\"] = adata_latent.X.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22390d3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vk = cr.kernels.VelocityKernel(adata_latent,\n",
    "                          xkey=\"X_latent\", \n",
    "                        vkey=\"velocity\").compute_transition_matrix()\n",
    "\n",
    "vk.compute_projection(basis=\"umap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5581d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "scv.pl.velocity_embedding_stream(adata_latent, vkey=\"T_fwd\", basis=\"umap\", color=\"experimental_time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7feb85b6",
   "metadata": {},
   "source": [
    "**Propagate with neural ODE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e1007f",
   "metadata": {},
   "outputs": [],
   "source": [
    "node = NeuralODE(\n",
    "    torch_wrapper(model), solver=\"dopri5\", sensitivity=\"adjoint\", atol=1e-4, rtol=1e-4\n",
    ")\n",
    "\n",
    "# Append first time point\n",
    "trajs = []\n",
    "with torch.no_grad():\n",
    "    X_pf = torch.from_numpy(X[0])\n",
    "    trajs.append(X_pf.unsqueeze(0))\n",
    "    for t in range(n_times-1):\n",
    "        traj = node.trajectory(X_pf.float().to(device),\n",
    "            t_span=torch.linspace(t, t+1, 400),\n",
    "        ).cpu()\n",
    "        X_pf = traj[-1]\n",
    "        trajs.append(X_pf.unsqueeze(0))\n",
    "\n",
    "trajs = torch.cat(trajs, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a504bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0143ad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pf = trajs.view(trajs.shape[0]*trajs.shape[1], -1)\n",
    "times = torch.arange(5).unsqueeze(1).expand(trajs.shape[0],trajs.shape[1]).ravel()\n",
    "times = pd.DataFrame(times)\n",
    "times.columns = [\"experimental_time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b309c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "times.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6056103f",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_pf = sc.AnnData(X=X_pf.cpu().numpy(), \n",
    "                     obs=times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bb20c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(adata_pf)\n",
    "sc.pp.neighbors(adata_pf)\n",
    "sc.tl.umap(adata_pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bf5d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata_pf, color=\"experimental_time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b91c57",
   "metadata": {},
   "source": [
    "Co-embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c6dd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_total = np.concatenate([adata_latent.X, X_pf], axis=0)\n",
    "dataset_type = [\"True\" for _ in range(adata_latent.X.shape[0])] + \\\n",
    "                [\"False\" for _ in range(X_pf.shape[0])]\n",
    "dataset_type = pd.DataFrame(dataset_type)\n",
    "dataset_type.columns = [\"Dataset_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6716f0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "adata_pf = sc.AnnData(X=X_total, \n",
    "                     obs=dataset_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9b1ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.tl.pca(adata_pf)\n",
    "sc.pp.neighbors(adata_pf)\n",
    "sc.tl.umap(adata_pf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1811a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.pl.umap(adata_pf, color=\"Dataset_type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6622af2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126d42e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "~ZC ZZ                                "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "d5240001f602d094a653e72667f1f126473feea48647f48d8a8ce2a6fb0c39cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
