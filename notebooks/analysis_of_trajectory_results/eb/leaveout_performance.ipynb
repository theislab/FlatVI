{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5f465612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paths import DATA_DIR, CKPT_FOLDER, PROJECT_FOLDER\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import scanpy as sc\n",
    "import sklearn\n",
    "import scvelo as scv\n",
    "\n",
    "import anndata\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display\n",
    "from torchdyn.core import NeuralODE\n",
    "\n",
    "from scCFM.datamodules.time_sc_datamodule import TrajectoryDataModule\n",
    "from scCFM.models.cfm.components.mlp import MLP\n",
    "from scCFM.models.cfm.cfm_module import CFMLitModule\n",
    "\n",
    "from scCFM.models.base.vae import VAE\n",
    "from scCFM.models.base.geometric_vae import GeometricNBVAE\n",
    "from scCFM.models.base.geodesic_ae import GeodesicAE\n",
    "\n",
    "from scCFM.datamodules.sc_datamodule import scDataModule\n",
    "from scCFM.models.cfm.components.eval.distribution_distances import compute_distribution_distances\n",
    "\n",
    "from notebooks.utils import decode_trajectory_single_step, standardize, compute_prdc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d363b9-65bc-4273-85d2-3cfaa07d3c4b",
   "metadata": {},
   "source": [
    "Initialize the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ccf4750",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0e1767-1abe-4746-afff-7439aeb0a2ab",
   "metadata": {},
   "source": [
    "Initialize datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4761425c-8b15-4610-9861-b88a1e70a3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule={'path': PROJECT_FOLDER / 'data/eb/processed/eb_phate.h5ad', \n",
    "            'x_layer': 'X_norm', \n",
    "            'cond_keys': ['experimental_time', 'leiden'],\n",
    "            'use_pca': False, \n",
    "            'n_dimensions': None, \n",
    "            'train_val_test_split': [1], \n",
    "            'batch_size': 512, \n",
    "            'num_workers': 2}\n",
    "\n",
    "# Initialize datamodule\n",
    "datamodule = scDataModule(**datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb402a71-f7a0-40f1-b3c0-f02fa51b7f59",
   "metadata": {},
   "source": [
    "Initialize autoencoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff8366d0-3098-4bb2-9296-ba78f1618957",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GeodesicAE(\n",
       "  (encoder_layers): MLP(\n",
       "    (net): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=1241, out_features=256, bias=True)\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder_layers): MLP(\n",
       "    (net): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=10, out_features=256, bias=True)\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ELU(alpha=1.0)\n",
       "      )\n",
       "      (1): Sequential(\n",
       "        (0): Linear(in_features=256, out_features=1241, bias=True)\n",
       "        (1): BatchNorm1d(1241, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder_mu_lib): Linear(in_features=256, out_features=1241, bias=True)\n",
       "  (latent_layer): Linear(in_features=256, out_features=10, bias=True)\n",
       "  (criterion): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vae_kwargs={'in_dim': datamodule.in_dim,\n",
    "       'n_epochs_anneal_kl': 1000, \n",
    "       'kl_weight': None, \n",
    "       'likelihood': 'nb', \n",
    "       'dropout': False, \n",
    "       'learning_rate': 0.001, \n",
    "       'dropout_p': False, \n",
    "       'model_library_size': True, \n",
    "       'batch_norm': True, \n",
    "       'kl_warmup_fraction': 0.1, \n",
    "       'hidden_dims': [256, 10]}\n",
    "        \n",
    "geometric_kwargs={'compute_metrics_every': 1, \n",
    "           'use_c': True, \n",
    "           'l2': True, \n",
    "           'eta_interp': 0, \n",
    "           'interpolate_z': False, \n",
    "           'start_jac_after': 0, \n",
    "           'fl_weight': 0.1,\n",
    "           'detach_theta': True}\n",
    "\n",
    "geodesic_kwargs={\"in_dim\": datamodule.in_dim,\n",
    "          \"hidden_dims\": [256, 10],\n",
    "          \"batch_norm\": True,\n",
    "          \"dropout\": False, \n",
    "          \"dropout_p\": False,\n",
    "          \"likelihood\": \"nb\",\n",
    "          \"learning_rate\": 0.001}\n",
    "\n",
    "# Initialize vae and geometric vae\n",
    "vae = GeometricNBVAE(**geometric_kwargs, vae_kwargs=vae_kwargs).to(device)\n",
    "geometric_vae = GeometricNBVAE(**geometric_kwargs, vae_kwargs=vae_kwargs).to(device)\n",
    "geodesic_ae = GeodesicAE(**geodesic_kwargs).to(device)\n",
    "\n",
    "# Load state dicts and put in eval mode \n",
    "vae.load_state_dict(torch.load(PROJECT_FOLDER / \"checkpoints/ae/eb/best_model_vae_lib.ckpt\")[\"state_dict\"])\n",
    "geometric_vae.load_state_dict(torch.load(PROJECT_FOLDER / \"checkpoints/ae/eb/best_model_geometric_lib.ckpt\")[\"state_dict\"])\n",
    "geodesic_ae.load_state_dict(torch.load(PROJECT_FOLDER / \"checkpoints/ae/eb/best_model_geodesic_ae.ckpt\")[\"state_dict\"])\n",
    "\n",
    "vae.eval()\n",
    "geometric_vae.eval()\n",
    "geodesic_ae.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceeb44a2-28ab-42ed-b5d3-327161629831",
   "metadata": {},
   "source": [
    "## Setup CFMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f8247cb-b681-4e82-8905-f3af83b2032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "leavout_timepoints_folder = CKPT_FOLDER / \"trajectory\" / \"eb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c4acf8-5ea9-4d9c-abdf-cbbc2d1312bf",
   "metadata": {},
   "source": [
    "Initialize datamodule for trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4273aa1-2490-4582-abc7-5219c2e5f09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule_kwargs_vae = {'path': PROJECT_FOLDER / 'data/eb/flat/eb_lib.h5ad',\n",
    "                          'x_layer': 'X_latents',\n",
    "                          'time_key': 'experimental_time', \n",
    "                          'use_pca': False, \n",
    "                          'n_dimensions': None, \n",
    "                          'train_val_test_split': [0.9, 0.1], \n",
    "                          'num_workers': 2, \n",
    "                          'batch_size': 512, \n",
    "                          'model_library_size': True}\n",
    "\n",
    "datamodule_kwargs_flat = {'path': PROJECT_FOLDER / 'data/eb/flat/eb_flat_lib.h5ad',\n",
    "                          'x_layer': 'X_latents',\n",
    "                          'time_key': 'experimental_time', \n",
    "                          'use_pca': False, \n",
    "                          'n_dimensions': None, \n",
    "                          'train_val_test_split': [0.9, 0.1], \n",
    "                          'num_workers': 2, \n",
    "                          'batch_size': 512, \n",
    "                           'model_library_size': True}\n",
    "\n",
    "datamodule_kwargs_geodesic= {'path': PROJECT_FOLDER / 'data/eb/flat/eb_geodesic.h5ad',\n",
    "                          'x_layer': 'X_latents',\n",
    "                          'time_key': 'experimental_time', \n",
    "                          'use_pca': False, \n",
    "                          'n_dimensions': None, \n",
    "                          'train_val_test_split': [0.9, 0.1], \n",
    "                          'num_workers': 2, \n",
    "                          'batch_size': 512, \n",
    "                           'model_library_size': True}\n",
    "\n",
    "# Initialize the datamodules \n",
    "datamodule_vae = TrajectoryDataModule(**datamodule_kwargs_vae)\n",
    "datamodule_flat = TrajectoryDataModule(**datamodule_kwargs_flat)\n",
    "datamodule_geodesic = TrajectoryDataModule(**datamodule_kwargs_geodesic)\n",
    "\n",
    "# Mapping real times to index\n",
    "idx2time = datamodule_vae.idx2time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e5828a",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1fa627-0299-49ea-b2a9-6309a3c491ef",
   "metadata": {},
   "source": [
    "First, read the latent space anndata and plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8d0bfee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read latent anndata\n",
    "adata_latent_vae = sc.read_h5ad(DATA_DIR / \"eb\" / \"flat\" / \"eb_lib.h5ad\")\n",
    "adata_latent_flat = sc.read_h5ad(DATA_DIR / \"eb\" / \"flat\" / \"eb_flat_lib.h5ad\")\n",
    "adata_latent_geodesic = sc.read_h5ad(DATA_DIR / \"eb\" / \"flat\" / \"eb_geodesic.h5ad\")\n",
    "\n",
    "# Read real anndata\n",
    "adata_eb_original = sc.read_h5ad(PROJECT_FOLDER / 'data/eb/processed/eb_phate.h5ad')\n",
    "sc.tl.pca(adata_eb_original, n_comps=50)\n",
    "adata_eb_original.X = adata_eb_original.layers[\"X_norm\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26176fd4-382d-480b-a396-d62368abd40e",
   "metadata": {},
   "source": [
    "Number of experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7b6d822e-1f8d-4af6-adda-2687dd127180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.0, 1: 0.25, 2: 0.5, 3: 0.75, 4: 1.0}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_timepoints = len(np.unique(adata_latent_vae.obs.experimental_time))\n",
    "idx2time = dict(zip(range(n_timepoints), np.unique(adata_latent_vae.obs.experimental_time)))\n",
    "idx2time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b70343",
   "metadata": {},
   "source": [
    "Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dcf2a556",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_hparams = {\"dim\": adata_latent_flat.X.shape[1]+1,\n",
    "                \"w\": 64,\n",
    "                \"time_varying\": True}\n",
    "\n",
    "cfm_kwargs = {'ot_sampler': 'exact', \n",
    "                   'sigma': 0.1, \n",
    "                   'use_real_time': False, \n",
    "                   'lr': 0.001, \n",
    "                   'antithetic_time_sampling': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d0cf44-7d54-49cc-95ec-7a2639a039a1",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b4c17f-40ac-43aa-a8bf-33f3424b6f33",
   "metadata": {},
   "source": [
    "Load checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "09f1696f-c361-4f88-9e4c-a7084f7bbdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaveput_ckpt_vae = {}\n",
    "leaveout_ckpt_flat = {}\n",
    "leaveout_ckpt_geodesic = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "9a10949a-5b84-4e06-b980-81cb1643dde8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time point 1\n",
      "predict latent trajectory\n",
      "{'precision': 0.5393893705239352, 'recall': 0.6461573650503202, 'density': 0.30976253298153034, 'coverage': 0.2381061299176578}\n",
      "{'precision': 0.846646571213263, 'recall': 0.7903890160183067, 'density': 0.645440844009043, 'coverage': 0.43157894736842106}\n",
      "{'precision': 0.3742932529212213, 'recall': 0.9338975297346752, 'density': 0.14346023369770072, 'coverage': 0.18412625800548948}\n",
      "{'precision': 0.0546345139412208, 'recall': 0.8988558352402746, 'density': 0.016126601356443105, 'coverage': 0.032494279176201374}\n",
      "Time point 2\n",
      "predict latent trajectory\n",
      "{'precision': 0.7152333028362305, 'recall': 0.736827661909989, 'density': 0.4806953339432754, 'coverage': 0.5532381997804611}\n",
      "{'precision': 0.9462242562929062, 'recall': 0.9368652209717266, 'density': 0.8555606407322656, 'coverage': 0.8210266264068076}\n",
      "{'precision': 0.3389752973467521, 'recall': 0.9179473106476399, 'density': 0.12872827081427266, 'coverage': 0.27497255762897915}\n",
      "{'precision': 0.05995423340961099, 'recall': 0.9022783420258029, 'density': 0.018443935926773455, 'coverage': 0.05956629151797969}\n",
      "Time point 3\n",
      "predict latent trajectory\n",
      "{'precision': 0.8290340285400659, 'recall': 0.8788506342221072, 'density': 0.6310647639956093, 'coverage': 0.664509448615066}\n",
      "{'precision': 0.9374142190502334, 'recall': 0.9472322814278323, 'density': 0.8670875651935218, 'coverage': 0.7904811174340404}\n",
      "{'precision': 0.38336992316136115, 'recall': 0.9189748899818794, 'density': 0.15384193194291987, 'coverage': 0.2756924669945638}\n",
      "{'precision': 0.05627230304693934, 'recall': 0.8960165545783756, 'density': 0.017567938512215206, 'coverage': 0.05406104500775996}\n"
     ]
    }
   ],
   "source": [
    "for tp in range(1, n_timepoints-1):\n",
    "    print(f\"Time point {tp}\")\n",
    "    #Pick time 0 observations\n",
    "    X_adata_t0_latent_vae = torch.from_numpy(adata_latent_vae[adata_latent_vae.obs[\"experimental_time\"]==idx2time[(tp-1)]].X).to(device)\n",
    "    X_adata_t0_latent_flat = torch.from_numpy(adata_latent_flat[adata_latent_flat.obs[\"experimental_time\"]==idx2time[(tp-1)]].X).to(device)\n",
    "    X_adata_t0_latent_geodesic = torch.from_numpy(adata_latent_geodesic[adata_latent_geodesic.obs[\"experimental_time\"]==idx2time[(tp-1)]].X).to(device)\n",
    "\n",
    "    # Pick observations next timepoint \n",
    "    X_adata_t1_latent_vae = torch.from_numpy(adata_latent_vae[adata_latent_vae.obs[\"experimental_time\"]==idx2time[tp]].X).to(device)\n",
    "    X_adata_t1_latent_flat = torch.from_numpy(adata_latent_flat[adata_latent_flat.obs[\"experimental_time\"]==idx2time[tp]].X).to(device)\n",
    "    X_adata_t1_latent_geodesic = torch.from_numpy(adata_latent_geodesic[adata_latent_geodesic.obs[\"experimental_time\"]==idx2time[tp]].X).to(device)    \n",
    "\n",
    "    # Collect PCs    \n",
    "    X_adata_real_pca = torch.from_numpy(adata_eb_original[adata_eb_original.obs[\"experimental_time\"]==idx2time[tp]].obsm[\"X_pca\"]).to(device)\n",
    "    X_adata_real = torch.from_numpy(adata_eb_original[adata_eb_original.obs[\"experimental_time\"]==idx2time[tp]].layers[\"X_log\"].A).to(device)\n",
    "\n",
    "    #Pick library sizes\n",
    "    l_t0_vae = adata_latent_vae.obs.loc[adata_latent_vae.obs[\"experimental_time\"]==idx2time[(tp-1)], \"log_library_size\"].to_numpy()\n",
    "    l_t0_flat = adata_latent_flat.obs.loc[adata_latent_flat.obs[\"experimental_time\"]==idx2time[(tp-1)], \"log_library_size\"].to_numpy()\n",
    "    l_t0_geodesic = adata_latent_geodesic.obs.loc[adata_latent_geodesic.obs[\"experimental_time\"]==idx2time[(tp-1)], \"log_library_size\"].to_numpy()\n",
    "\n",
    "    #Pick library sizes\n",
    "    l_t0_vae = torch.from_numpy(l_t0_vae).to(device)\n",
    "    l_t0_flat = torch.from_numpy(l_t0_flat).to(device)\n",
    "    l_t0_geodesic = torch.from_numpy(l_t0_geodesic).to(device)\n",
    "\n",
    "    # Initialize nets\n",
    "    net_vae = MLP(**net_hparams).to(device)\n",
    "    net_flat = MLP(**net_hparams).to(device)\n",
    "    net_geodesic = MLP(**net_hparams).to(device)\n",
    "    cfm_vae = CFMLitModule(net=net_vae, datamodule=datamodule_vae, **cfm_kwargs).to(device)\n",
    "    cfm_flat = CFMLitModule(net=net_flat, datamodule=datamodule_flat, **cfm_kwargs).to(device)\n",
    "    cfm_geodesic = CFMLitModule(net=net_geodesic, datamodule=datamodule_geodesic, **cfm_kwargs).to(device)\n",
    "\n",
    "    # Read the checkpoints\n",
    "    cfm_vae.load_state_dict(torch.load(leavout_timepoints_folder / f\"eb_vae_leaveout_{tp}.ckpt\")[\"state_dict\"])\n",
    "    cfm_flat.load_state_dict(torch.load(leavout_timepoints_folder / f\"eb_flat_leaveout_{tp}.ckpt\")[\"state_dict\"])\n",
    "    cfm_geodesic.load_state_dict(torch.load(leavout_timepoints_folder / f\"eb_geodesic_leaveout_{tp}.ckpt\")[\"state_dict\"])\n",
    "\n",
    "    _, X_adata_predicted_vae, X_adata_latent_vae = decode_trajectory_single_step(X_adata_t0_latent_vae, \n",
    "                                                                                 l_t0_vae, \n",
    "                                                                                 tp-1, \n",
    "                                                                                 cfm_vae, \n",
    "                                                                                 vae)\n",
    "                                                                                \n",
    "    _, X_adata_predicted_flat, X_adata_latent_flat = decode_trajectory_single_step(X_adata_t0_latent_flat, \n",
    "                                                                                   l_t0_flat, \n",
    "                                                                                   tp-1, \n",
    "                                                                                   cfm_flat, \n",
    "                                                                                   geometric_vae)\n",
    "                                                                                  \n",
    "    _, X_adata_predicted_geodesic, X_adata_latent_geodesic = decode_trajectory_single_step(X_adata_t0_latent_geodesic, \n",
    "                                                                                           l_t0_geodesic, \n",
    "                                                                                           tp-1, \n",
    "                                                                                           cfm_geodesic, \n",
    "                                                                                           geodesic_ae, \n",
    "                                                                                           model_type=\"geodesic_ae\")\n",
    "\n",
    "    print(\"predict latent trajectory\")\n",
    "    X_adata_t1_latent_vae, X_adata_latent_vae = cross_standardize(X_adata_t1_latent_vae, X_adata_latent_vae[:,:-1])\n",
    "    X_adata_t1_latent_flat, X_adata_latent_flat = cross_standardize(X_adata_t1_latent_flat, X_adata_latent_flat[:,:-1])\n",
    "                                                                                   \n",
    "    # print(compute_distribution_distances(X_adata_t1_latent_vae.unsqueeze(1).to(\"cpu\"), \n",
    "    #                                      X_adata_latent_vae.unsqueeze(1).to(\"cpu\")))\n",
    "    # print(compute_distribution_distances(X_adata_t1_latent_flat.unsqueeze(1).to(\"cpu\"),\n",
    "    #                                      X_adata_latent_flat.unsqueeze(1).to(\"cpu\")))\n",
    "    print(compute_prdc(X_adata_t1_latent_vae.to(\"cpu\"), X_adata_latent_vae.to(\"cpu\"), nearest_k=5))\n",
    "    print(compute_prdc(X_adata_t1_latent_flat.to(\"cpu\"), X_adata_latent_flat.to(\"cpu\"), nearest_k=5))\n",
    "    print(compute_prdc(X_adata_t1_latent_vae.to(\"cpu\"), torch.randn_like(X_adata_latent_vae.to(\"cpu\")), nearest_k=5))\n",
    "    print(compute_prdc(X_adata_t1_latent_flat.to(\"cpu\"), torch.randn_like(X_adata_latent_flat.to(\"cpu\")), nearest_k=5))\n",
    "    \n",
    "    # print(compute_distribution_distances(standardize(X_adata_t1_latent_vae).unsqueeze(1).to(\"cpu\"), \n",
    "    #                                      standardize(X_adata_latent_vae[:,:-1]).unsqueeze(1).to(\"cpu\")))\n",
    "    # print(compute_distribution_distances(standardize(X_adata_t1_latent_flat).unsqueeze(1).to(\"cpu\"),\n",
    "    #                                      standardize(X_adata_latent_flat[:,:-1]).unsqueeze(1).to(\"cpu\")))\n",
    "    # print(compute_distribution_distances(standardize(X_adata_t1_latent_geodesic).unsqueeze(1).to(\"cpu\"),\n",
    "    #                                      standardize(X_adata_latent_geodesic[:,:-1]).unsqueeze(1).to(\"cpu\")))\n",
    "\n",
    "\n",
    "    # print(\"predict decoded trajectory\")\n",
    "    # X_adata_predicted_vae = anndata.AnnData(X=X_adata_predicted_vae.numpy())\n",
    "    # X_adata_predicted_flat = anndata.AnnData(X=X_adata_predicted_flat.numpy())\n",
    "    # X_adata_predicted_geodesic = anndata.AnnData(X=X_adata_predicted_geodesic.numpy())\n",
    "    # sc.pp.log1p(X_adata_predicted_vae)\n",
    "    # sc.pp.log1p(X_adata_predicted_flat)\n",
    "    # sc.tl.pca(X_adata_predicted_vae, n_comps=50)\n",
    "    # sc.tl.pca(X_adata_predicted_flat, n_comps=50)\n",
    "    # sc.tl.pca(X_adata_predicted_geodesic, n_comps=50)\n",
    "\n",
    "    # print(compute_prdc(torch.from_numpy(X_adata_predicted_vae.obsm[\"X_pca\"]), \n",
    "    #                                          X_adata_real_pca.to(\"cpu\"), nearest_k=30))\n",
    "    # print(compute_prdc(torch.from_numpy(X_adata_predicted_flat.obsm[\"X_pca\"]), \n",
    "    #                                          X_adata_real_pca.to(\"cpu\"), nearest_k=30))\n",
    "    # print(compute_prdc(torch.from_numpy(X_adata_predicted_geodesic.obsm[\"X_pca\"]), \n",
    "    #                                          X_adata_real_pca.to(\"cpu\"), nearest_k=30))\n",
    "    # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a2a8adcb-3d2c-4485-8997-48cc175d8c25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-Wasserstein</td>\n",
       "      <td>2-Wasserstein</td>\n",
       "      <td>Linear_MMD</td>\n",
       "      <td>Poly_MMD</td>\n",
       "      <td>RBF_MMD</td>\n",
       "      <td>Mean_MSE</td>\n",
       "      <td>Mean_L2</td>\n",
       "      <td>Mean_L1</td>\n",
       "      <td>Median_MSE</td>\n",
       "      <td>Median_L2</td>\n",
       "      <td>Median_L1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.251247</td>\n",
       "      <td>1.326609</td>\n",
       "      <td>0.052445</td>\n",
       "      <td>0.229008</td>\n",
       "      <td>0.208673</td>\n",
       "      <td>0.069506</td>\n",
       "      <td>0.263639</td>\n",
       "      <td>0.241806</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0              1           2         3         4         5   \\\n",
       "0  1-Wasserstein  2-Wasserstein  Linear_MMD  Poly_MMD   RBF_MMD  Mean_MSE   \n",
       "1       1.251247       1.326609    0.052445  0.229008  0.208673  0.069506   \n",
       "\n",
       "         6         7           8          9          10  \n",
       "0   Mean_L2   Mean_L1  Median_MSE  Median_L2  Median_L1  \n",
       "1  0.263639  0.241806        None       None       None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(compute_distribution_distances(X_adata_t1_latent_flat.unsqueeze(1).to(\"cpu\"),\n",
    "                                         X_adata_latent_flat.unsqueeze(1).to(\"cpu\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "82decb91-af08-4425-b237-ca51a9994045",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1-Wasserstein</td>\n",
       "      <td>2-Wasserstein</td>\n",
       "      <td>Linear_MMD</td>\n",
       "      <td>Poly_MMD</td>\n",
       "      <td>RBF_MMD</td>\n",
       "      <td>Mean_MSE</td>\n",
       "      <td>Mean_L2</td>\n",
       "      <td>Mean_L1</td>\n",
       "      <td>Median_MSE</td>\n",
       "      <td>Median_L2</td>\n",
       "      <td>Median_L1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.811036</td>\n",
       "      <td>1.933194</td>\n",
       "      <td>0.082131</td>\n",
       "      <td>0.286585</td>\n",
       "      <td>0.217289</td>\n",
       "      <td>0.073672</td>\n",
       "      <td>0.271425</td>\n",
       "      <td>0.207192</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0              1           2         3         4         5   \\\n",
       "0  1-Wasserstein  2-Wasserstein  Linear_MMD  Poly_MMD   RBF_MMD  Mean_MSE   \n",
       "1       1.811036       1.933194    0.082131  0.286585  0.217289  0.073672   \n",
       "\n",
       "         6         7           8          9          10  \n",
       "0   Mean_L2   Mean_L1  Median_MSE  Median_L2  Median_L1  \n",
       "1  0.271425  0.207192        None       None       None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.DataFrame(compute_distribution_distances(X_adata_t1_latent_vae.unsqueeze(1).to(\"cpu\"),\n",
    "                                         X_adata_latent_vae.unsqueeze(1).to(\"cpu\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "769a094f-fa72-403b-aa58-cc76d3457a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_standardize(tensor1, tensor2):\n",
    "    \"\"\"\n",
    "    Standardize tensor across the rows\n",
    "    \"\"\"\n",
    "    mean_t1, std_t1 = tensor1.mean(0), tensor1.std(0)\n",
    "    tensor1 = (tensor1 - mean_t1) / (std_t1 + 1e-6)\n",
    "    tensor2 = (tensor2 - mean_t1) / (std_t1 + 1e-6)\n",
    "    return tensor1, tensor2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0141497-4615-46c1-9494-e636798499cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbdad5d-cfc1-44b0-9dbe-e7fcad097b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a1e4c5a2-cf46-4327-93e9-69cf0586baae",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"/home/icb/alessandro.palma/environment/scCFM/scCFM/train_hydra/multirun/2023-09-23/17-38-14/.submitit/13690774_0/13690774_0_submitted.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "a18b1c42-d74a-4ce3-8f34-92fd20ae4e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open(f, \"rb\") as file:\n",
    "    f = pkl.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "87a9e64d-6e5a-42eb-9216-f90301681348",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'function': <hydra_plugins.hydra_submitit_launcher.submitit_launcher.SlurmLauncher at 0x7fee84bff640>,\n",
       " 'args': (['model.leaveout_timepoint=2',\n",
       "   'hydra=CFM_schiebinger_leaveout',\n",
       "   'datamodule=CFM_schiebinger_leaveout',\n",
       "   'logger=CFM_schiebinger_leaveout',\n",
       "   'train=CFM_schiebinger_leaveout'],\n",
       "  'hydra.sweep.dir',\n",
       "  0,\n",
       "  'job_id_for_0',\n",
       "  {'instances': {hydra.core.config_store.ConfigStore: <hydra.core.config_store.ConfigStore at 0x7feecd936f20>,\n",
       "    hydra.version.VersionBase: <hydra.version.VersionBase at 0x7feecd947430>,\n",
       "    hydra._internal.sources_registry.SourcesRegistry: <hydra._internal.sources_registry.SourcesRegistry at 0x7feecd947550>,\n",
       "    hydra.core.utils.JobRuntime: <hydra.core.utils.JobRuntime at 0x7feecd9475b0>,\n",
       "    hydra.core.global_hydra.GlobalHydra: <hydra.core.global_hydra.GlobalHydra at 0x7feecd9476d0>},\n",
       "   'omegaconf_resolvers': {'oc.create': <function omegaconf.omegaconf.OmegaConf.register_new_resolver.<locals>.resolver_wrapper(config: omegaconf.basecontainer.BaseContainer, parent: omegaconf.base.Container, node: omegaconf.base.Node, args: Tuple[Any, ...], args_str: Tuple[str, ...]) -> Any>,\n",
       "    'oc.decode': <function omegaconf.omegaconf.OmegaConf.register_new_resolver.<locals>.resolver_wrapper(config: omegaconf.basecontainer.BaseContainer, parent: omegaconf.base.Container, node: omegaconf.base.Node, args: Tuple[Any, ...], args_str: Tuple[str, ...]) -> Any>,\n",
       "    'oc.deprecated': <function omegaconf.omegaconf.OmegaConf.register_new_resolver.<locals>.resolver_wrapper(config: omegaconf.basecontainer.BaseContainer, parent: omegaconf.base.Container, node: omegaconf.base.Node, args: Tuple[Any, ...], args_str: Tuple[str, ...]) -> Any>,\n",
       "    'oc.env': <function omegaconf.omegaconf.OmegaConf.register_new_resolver.<locals>.resolver_wrapper(config: omegaconf.basecontainer.BaseContainer, parent: omegaconf.base.Container, node: omegaconf.base.Node, args: Tuple[Any, ...], args_str: Tuple[str, ...]) -> Any>,\n",
       "    'oc.select': <function omegaconf.omegaconf.OmegaConf.register_new_resolver.<locals>.resolver_wrapper(config: omegaconf.basecontainer.BaseContainer, parent: omegaconf.base.Container, node: omegaconf.base.Node, args: Tuple[Any, ...], args_str: Tuple[str, ...]) -> Any>,\n",
       "    'oc.dict.keys': <function omegaconf.omegaconf.OmegaConf.register_new_resolver.<locals>.resolver_wrapper(config: omegaconf.basecontainer.BaseContainer, parent: omegaconf.base.Container, node: omegaconf.base.Node, args: Tuple[Any, ...], args_str: Tuple[str, ...]) -> Any>,\n",
       "    'oc.dict.values': <function omegaconf.omegaconf.OmegaConf.register_new_resolver.<locals>.resolver_wrapper(config: omegaconf.basecontainer.BaseContainer, parent: omegaconf.base.Container, node: omegaconf.base.Node, args: Tuple[Any, ...], args_str: Tuple[str, ...]) -> Any>,\n",
       "    'now': <function omegaconf.omegaconf.OmegaConf.register_new_resolver.<locals>.resolver_wrapper(config: omegaconf.basecontainer.BaseContainer, parent: omegaconf.base.Container, node: omegaconf.base.Node, args: Tuple[Any, ...], args_str: Tuple[str, ...]) -> Any>,\n",
       "    'hydra': <function omegaconf.omegaconf.OmegaConf.register_new_resolver.<locals>.resolver_wrapper(config: omegaconf.basecontainer.BaseContainer, parent: omegaconf.base.Container, node: omegaconf.base.Node, args: Tuple[Any, ...], args_str: Tuple[str, ...]) -> Any>,\n",
       "    'python_version': <function omegaconf.omegaconf.OmegaConf.register_new_resolver.<locals>.resolver_wrapper(config: omegaconf.basecontainer.BaseContainer, parent: omegaconf.base.Container, node: omegaconf.base.Node, args: Tuple[Any, ...], args_str: Tuple[str, ...]) -> Any>}}),\n",
       " 'kwargs': {},\n",
       " '_result': None,\n",
       " '_done': False,\n",
       " '_timeout_min': 1440,\n",
       " '_timeout_countdown': 0}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf23006-1490-4402-abc5-37ba29674b44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
