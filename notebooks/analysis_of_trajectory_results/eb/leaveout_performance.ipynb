{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f465612",
   "metadata": {},
   "outputs": [],
   "source": [
    "from paths import DATA_DIR, CKPT_FOLDER, PROJECT_FOLDER\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import scanpy as sc\n",
    "import sklearn\n",
    "import scvelo as scv\n",
    "\n",
    "import anndata\n",
    "import pandas as pd\n",
    "\n",
    "from torchdyn.core import NeuralODE\n",
    "\n",
    "from scCFM.datamodules.time_sc_datamodule import TrajectoryDataModule\n",
    "from scCFM.models.cfm.components.mlp import MLP\n",
    "from scCFM.models.cfm.cfm_module import CFMLitModule\n",
    "from scCFM.models.base.vae import VAE\n",
    "from scCFM.models.base.geometric_vae import GeometricNBVAE\n",
    "from scCFM.datamodules.sc_datamodule import scDataModule\n",
    "from scCFM.models.cfm.components.eval.distribution_distances import compute_distribution_distances\n",
    "\n",
    "from notebooks.utils import decode_trajectory_single_step\n",
    "\n",
    "import scib_metrics\n",
    "from scib_metrics.benchmark import Benchmarker, BatchCorrection, BioConservation\n",
    "from scib_metrics import silhouette_batch, ilisi_knn, clisi_knn, kbet, graph_connectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ccf4750",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afc80e17-0e55-419f-a601-92ef71dfdd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(tensor):\n",
    "    tensor = (tensor - tensor.mean(0)) / tensor.std(0)+1e-6\n",
    "    return tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cd1d0e5-a9da-41fd-9ea0-e0b0e861da6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_pairwise_distance(data_x, data_y=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        data_x: numpy.ndarray([N, feature_dim], dtype=np.float32)\n",
    "        data_y: numpy.ndarray([N, feature_dim], dtype=np.float32)\n",
    "    Returns:\n",
    "        numpy.ndarray([N, N], dtype=np.float32) of pairwise distances.\n",
    "    \"\"\"\n",
    "    if data_y is None:\n",
    "        data_y = data_x\n",
    "    dists = sklearn.metrics.pairwise_distances(\n",
    "        data_x, data_y, metric='euclidean', n_jobs=8)\n",
    "    return dists\n",
    "\n",
    "\n",
    "def get_kth_value(unsorted, k, axis=-1):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        unsorted: numpy.ndarray of any dimensionality.\n",
    "        k: int\n",
    "    Returns:\n",
    "        kth values along the designated axis.\n",
    "    \"\"\"\n",
    "    # Take only K nearest neighbors and the radius is the maximum of the knn distances \n",
    "    indices = np.argpartition(unsorted, k, axis=axis)[..., :k]\n",
    "    k_smallests = np.take_along_axis(unsorted, indices, axis=axis)\n",
    "    kth_values = k_smallests.max(axis=axis)\n",
    "    return kth_values\n",
    "\n",
    "\n",
    "def compute_nearest_neighbour_distances(input_features, nearest_k):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        input_features: numpy.ndarray([N, feature_dim], dtype=np.float32)\n",
    "        nearest_k: int\n",
    "    Returns:\n",
    "        Distances to kth nearest neighbours.\n",
    "    \"\"\"\n",
    "    distances = compute_pairwise_distance(input_features)\n",
    "    radii = get_kth_value(distances, k=nearest_k + 1, axis=-1)\n",
    "    return radii\n",
    "\n",
    "\n",
    "def compute_prdc(real_features, fake_features, nearest_k):\n",
    "    \"\"\"\n",
    "    Computes precision, recall, density, and coverage given two manifolds.\n",
    "    Args:\n",
    "        real_features: numpy.ndarray([N, feature_dim], dtype=np.float32)\n",
    "        fake_features: numpy.ndarray([N, feature_dim], dtype=np.float32)\n",
    "        nearest_k: int.\n",
    "    Returns:\n",
    "        dict of precision, recall, density, and coverage.\n",
    "    \"\"\"\n",
    "    real_nearest_neighbour_distances = compute_nearest_neighbour_distances(\n",
    "        real_features, nearest_k)\n",
    "    fake_nearest_neighbour_distances = compute_nearest_neighbour_distances(\n",
    "        fake_features, nearest_k)\n",
    "    distance_real_fake = compute_pairwise_distance(\n",
    "        real_features, fake_features)\n",
    "\n",
    "    precision = (\n",
    "            distance_real_fake <\n",
    "            np.expand_dims(real_nearest_neighbour_distances, axis=1)\n",
    "    ).any(axis=0).mean()\n",
    "\n",
    "    recall = (\n",
    "            distance_real_fake <\n",
    "            np.expand_dims(fake_nearest_neighbour_distances, axis=0)\n",
    "    ).any(axis=1).mean()\n",
    "\n",
    "    density = (1. / float(nearest_k)) * (\n",
    "            distance_real_fake <\n",
    "            np.expand_dims(real_nearest_neighbour_distances, axis=1)\n",
    "    ).sum(axis=0).mean()\n",
    "\n",
    "    coverage = (\n",
    "            distance_real_fake.min(axis=1) <\n",
    "            real_nearest_neighbour_distances\n",
    "    ).mean()\n",
    "\n",
    "    return dict(precision=precision, \n",
    "                recall=recall,\n",
    "                density=density, \n",
    "                coverage=coverage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51f15f2-0f65-459b-9a9a-0e0acceffb05",
   "metadata": {},
   "source": [
    "## Initialize VAEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ff8366d0-3098-4bb2-9296-ba78f1618957",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GeometricNBVAE(\n",
       "  (encoder_layers): MLP(\n",
       "    (net): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=1241, out_features=256, bias=True)\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decoder_layers): MLP(\n",
       "    (net): Sequential(\n",
       "      (0): Sequential(\n",
       "        (0): Linear(in_features=10, out_features=256, bias=True)\n",
       "        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (2): ELU(alpha=1.0)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (library_size_decoder): Linear(in_features=10, out_features=1, bias=True)\n",
       "  (decoder_mu_lib): Linear(in_features=256, out_features=1241, bias=True)\n",
       "  (mu_logvar): Linear(in_features=256, out_features=20, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datamodule={'path': PROJECT_FOLDER / 'data/eb/processed/eb_phate.h5ad', \n",
    "            'x_layer': 'X_norm', \n",
    "            'cond_keys': ['experimental_time', 'leiden'],\n",
    "            'use_pca': False, \n",
    "            'n_dimensions': None, \n",
    "            'train_val_test_split': [1], \n",
    "            'batch_size': 512, \n",
    "            'num_workers': 2}\n",
    "\n",
    "# Initialize datamodule\n",
    "datamodule = scDataModule(**datamodule)\n",
    "\n",
    "model_vae={\n",
    "       'in_dim': datamodule.in_dim,\n",
    "       'n_epochs_anneal_kl': 1000, \n",
    "       'kl_weight': None, \n",
    "       'likelihood': 'nb', \n",
    "       'dropout': False, \n",
    "       'learning_rate': 0.001, \n",
    "       'dropout_p': False, \n",
    "       'model_library_size': True, \n",
    "       'batch_norm': True, \n",
    "       'kl_warmup_fraction': 0.1, \n",
    "       'hidden_dims': [256, 10]}\n",
    "        \n",
    "geometric={'compute_metrics_every': 1, \n",
    "           'use_c': True, \n",
    "           'l2': True, \n",
    "           'eta_interp': 0, \n",
    "           'interpolate_z': False, \n",
    "           'start_jac_after': 0, \n",
    "           'fl_weight': 0.1,\n",
    "           'detach_theta': True}\n",
    "\n",
    "# Initialize vae and geometric vae\n",
    "vae = GeometricNBVAE(**geometric, vae_kwargs=model_vae).to(device)\n",
    "geometric_vae = GeometricNBVAE(**geometric, vae_kwargs=model_vae).to(device)\n",
    "\n",
    "# Load state dicts and put in eval mode \n",
    "vae.load_state_dict(torch.load(PROJECT_FOLDER / \"checkpoints/ae/eb/best_model_vae_lib.ckpt\")[\"state_dict\"])\n",
    "geometric_vae.load_state_dict(torch.load(PROJECT_FOLDER / \"checkpoints/ae/eb/best_model_geometric_lib.ckpt\")[\"state_dict\"])\n",
    "vae.eval()\n",
    "geometric_vae.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceeb44a2-28ab-42ed-b5d3-327161629831",
   "metadata": {},
   "source": [
    "## Setup CFMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f8247cb-b681-4e82-8905-f3af83b2032a",
   "metadata": {},
   "outputs": [],
   "source": [
    "leavout_timepoints_folder = CKPT_FOLDER / \"trajectory\" / \"eb\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c4acf8-5ea9-4d9c-abdf-cbbc2d1312bf",
   "metadata": {},
   "source": [
    "Initialize datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4273aa1-2490-4582-abc7-5219c2e5f09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "datamodule_kwargs_vae = {'path': PROJECT_FOLDER / 'data/eb/flat/eb_lib.h5ad',\n",
    "                          'x_layer': 'X_latents',\n",
    "                          'time_key': 'experimental_time', \n",
    "                          'use_pca': False, \n",
    "                          'n_dimensions': None, \n",
    "                          'train_val_test_split': [0.9, 0.1], \n",
    "                          'num_workers': 2, \n",
    "                          'batch_size': 512, \n",
    "                          'model_library_size': True}\n",
    "\n",
    "datamodule_kwargs_flat = {'path': PROJECT_FOLDER / 'data/eb/flat/eb_flat_lib.h5ad',\n",
    "                          'x_layer': 'X_latents',\n",
    "                          'time_key': 'experimental_time', \n",
    "                          'use_pca': False, \n",
    "                          'n_dimensions': None, \n",
    "                          'train_val_test_split': [0.9, 0.1], \n",
    "                          'num_workers': 2, \n",
    "                          'batch_size': 512, \n",
    "                           'model_library_size': True}\n",
    "\n",
    "# Initialize the datamodules \n",
    "datamodule_vae = TrajectoryDataModule(**datamodule_kwargs_vae)\n",
    "datamodule_flat = TrajectoryDataModule(**datamodule_kwargs_flat)\n",
    "\n",
    "# Mapping real times to index\n",
    "idx2time = datamodule_vae.idx2time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e5828a",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1fa627-0299-49ea-b2a9-6309a3c491ef",
   "metadata": {},
   "source": [
    "First, read the latent space anndata and plot the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d0bfee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read latent anndata\n",
    "adata_latent_vae = sc.read_h5ad(DATA_DIR / \"eb\" / \"flat\" / \"eb_lib.h5ad\")\n",
    "adata_latent_flat = sc.read_h5ad(DATA_DIR / \"eb\" / \"flat\" / \"eb_flat_lib.h5ad\")\n",
    "\n",
    "# Read real anndata\n",
    "adata_eb_original = sc.read_h5ad(PROJECT_FOLDER / 'data/eb/processed/eb_phate.h5ad')\n",
    "sc.tl.pca(adata_eb_original, n_comps=200)\n",
    "adata_eb_original.X = adata_eb_original.layers[\"X_norm\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26176fd4-382d-480b-a396-d62368abd40e",
   "metadata": {},
   "source": [
    "Number of experiments "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7b6d822e-1f8d-4af6-adda-2687dd127180",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.0, 1: 0.25, 2: 0.5, 3: 0.75, 4: 1.0}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_timepoints = len(np.unique(adata_latent_vae.obs.experimental_time))\n",
    "idx2time = dict(zip(range(n_timepoints), np.unique(adata_latent_vae.obs.experimental_time)))\n",
    "idx2time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b70343",
   "metadata": {},
   "source": [
    "Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcf2a556",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_hparams = {\"dim\": adata_latent_flat.X.shape[1]+1,\n",
    "                \"w\": 64,\n",
    "                \"time_varying\": True}\n",
    "\n",
    "cfm_kwargs = {'ot_sampler': 'exact', \n",
    "                   'sigma': 0.1, \n",
    "                   'use_real_time': False, \n",
    "                   'lr': 0.001, \n",
    "                   'antithetic_time_sampling': True}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d0cf44-7d54-49cc-95ec-7a2639a039a1",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55b4c17f-40ac-43aa-a8bf-33f3424b6f33",
   "metadata": {},
   "source": [
    "Load checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09f1696f-c361-4f88-9e4c-a7084f7bbdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaveput_ckpt_vae = {}\n",
    "leaveout_ckpt_flat = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a10949a-5b84-4e06-b980-81cb1643dde8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for tp in range(1, n_timepoints-1):\n",
    "    print(f\"Time point {tp}\")\n",
    "    #Pick time 0 observations\n",
    "    X_adata_t0_latent_vae = torch.from_numpy(adata_latent_vae[adata_latent_vae.obs[\"experimental_time\"]==idx2time[(tp-1)]].X).to(device)\n",
    "    X_adata_t0_latent_flat = torch.from_numpy(adata_latent_flat[adata_latent_flat.obs[\"experimental_time\"]==idx2time[(tp-1)]].X).to(device)\n",
    "    X_adata_t1_latent_vae = torch.from_numpy(adata_latent_vae[adata_latent_vae.obs[\"experimental_time\"]==idx2time[tp]].X).to(device)\n",
    "    X_adata_t1_latent_flat = torch.from_numpy(adata_latent_flat[adata_latent_flat.obs[\"experimental_time\"]==idx2time[tp]].X).to(device)\n",
    "    X_adata_real_pca = torch.from_numpy(adata_eb_original[adata_eb_original.obs[\"experimental_time\"]==idx2time[tp]].obsm[\"X_pca\"]).to(device)\n",
    "    X_adata_real = torch.from_numpy(adata_eb_original[adata_eb_original.obs[\"experimental_time\"]==idx2time[tp]].layers[\"X_log\"].A).to(device)\n",
    "\n",
    "    #Pick library sizes\n",
    "    l_t0_vae = adata_latent_vae.obs.loc[adata_latent_vae.obs[\"experimental_time\"]==idx2time[(tp-1)], \"log_library_size\"].to_numpy()\n",
    "    l_t0_flat = adata_latent_flat.obs.loc[adata_latent_flat.obs[\"experimental_time\"]==idx2time[(tp-1)], \"log_library_size\"].to_numpy()\n",
    "    l_t0_vae = torch.from_numpy(l_t0_vae).to(device)\n",
    "    l_t0_flat = torch.from_numpy(l_t0_flat).to(device)\n",
    "\n",
    "    # Initialize nets\n",
    "    net_vae = MLP(**net_hparams).to(device)\n",
    "    net_flat = MLP(**net_hparams).to(device)\n",
    "    cfm_vae = CFMLitModule(net=net_vae, datamodule=datamodule_vae, **cfm_kwargs).to(device)\n",
    "    cfm_flat = CFMLitModule(net=net_flat, datamodule=datamodule_flat, **cfm_kwargs).to(device)\n",
    "\n",
    "    # Read the checkpoints\n",
    "    cfm_vae.load_state_dict(torch.load(leavout_timepoints_folder / f\"eb_vae_leaveout_{tp}.ckpt\")[\"state_dict\"])\n",
    "    cfm_flat.load_state_dict(torch.load(leavout_timepoints_folder / f\"eb_flat_leaveout_{tp}.ckpt\")[\"state_dict\"])\n",
    "\n",
    "    _, X_adata_predicted_vae, X_adata_latent_vae = decode_trajectory_single_step(X_adata_t0_latent_vae, l_t0_vae, tp-1, cfm_vae, vae)\n",
    "    _, X_adata_predicted_flat, X_adata_latent_flat = decode_trajectory_single_step(X_adata_t0_latent_flat, l_t0_flat, tp-1, cfm_flat, geometric_vae)\n",
    "\n",
    "    print(\"predict latent trajectory\")\n",
    "    print(compute_distribution_distances(standardize(X_adata_t1_latent_vae.unsqueeze(1).to(\"cpu\")), \n",
    "                                         standardize(X_adata_latent_vae[:,:-1].unsqueeze(1).to(\"cpu\"))))\n",
    "    print(compute_distribution_distances(standardize(X_adata_t1_latent_flat.unsqueeze(1).to(\"cpu\")),\n",
    "                                         standardize(X_adata_latent_flat[:,:-1].unsqueeze(1).to(\"cpu\"))))\n",
    "\n",
    "    print(\"predict decoded trajectory\")\n",
    "    X_adata_predicted_vae = anndata.AnnData(X=X_adata_predicted_vae.numpy())\n",
    "    X_adata_predicted_flat = anndata.AnnData(X=X_adata_predicted_flat.numpy())\n",
    "    sc.pp.log1p(X_adata_predicted_vae)\n",
    "    sc.pp.log1p(X_adata_predicted_flat)\n",
    "    sc.tl.pca(X_adata_predicted_vae, n_comps=200)\n",
    "    sc.tl.pca(X_adata_predicted_flat, n_comps=200)\n",
    "    \n",
    "    # print(compute_distribution_distances(torch.from_numpy(X_adata_predicted_vae.X).unsqueeze(1), \n",
    "    #                                      X_adata_real.unsqueeze(1).to(\"cpu\")))\n",
    "    # print(compute_distribution_distances(torch.from_numpy(X_adata_predicted_flat.X).unsqueeze(1), \n",
    "    #                                                       X_adata_real.unsqueeze(1).to(\"cpu\")))\n",
    "    \n",
    "    print(compute_distribution_distances(torch.from_numpy(X_adata_predicted_vae.obsm[\"X_pca\"]).unsqueeze(1), \n",
    "                                             X_adata_real_pca.unsqueeze(1).to(\"cpu\")))\n",
    "    print(compute_distribution_distances(torch.from_numpy(X_adata_predicted_flat.obsm[\"X_pca\"]).unsqueeze(1), \n",
    "                                             X_adata_real_pca.unsqueeze(1).to(\"cpu\")))\n",
    "\n",
    "    print(compute_prdc(torch.from_numpy(X_adata_predicted_vae.obsm[\"X_pca\"]), \n",
    "                                             X_adata_real_pca.to(\"cpu\"), nearest_k=30))\n",
    "    print(compute_prdc(torch.from_numpy(X_adata_predicted_flat.obsm[\"X_pca\"]), \n",
    "                                             X_adata_real_pca.to(\"cpu\"), nearest_k=30))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3962903-fecd-4358-8ada-98f0a40c1736",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62d86ddd-f28d-4068-90a1-df6206b20328",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
