WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1695476148.831368 1538433 tfrt_cpu_pjrt_client.cc:349] TfrtCpuClient created.
No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
/home/icb/alessandro.palma/miniconda3/envs/scCFM/lib/python3.10/site-packages/scvi/_settings.py:63: UserWarning: Since v1.0.0, scvi-tools no longer uses a random seed by default. Run `scvi.settings.seed = 0` to reproduce results from previous versions.
  self.seed = seed
/home/icb/alessandro.palma/miniconda3/envs/scCFM/lib/python3.10/site-packages/scvi/_settings.py:70: UserWarning: Setting `dl_pin_memory_gpu_training` is deprecated in v1.0 and will be removed in v1.1. Please pass in `pin_memory` to the data loaders instead.
  self.dl_pin_memory_gpu_training = (
wandb: Currently logged in as: allepalma. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.10
wandb: Run data is saved locally in /home/icb/alessandro.palma/environment/scCFM/project_dir/experiments/2_OFFICIAL_cfm_hein_latent_geodesic_LEAVEOUT/wandb/run-20230923_153602-27xfm3tg
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run lunar-lion-3
wandb: ⭐️ View project at https://wandb.ai/allepalma/2_OFFICIAL_cfm_hein_latent_geodesic_leaveout
wandb: 🚀 View run at https://wandb.ai/allepalma/2_OFFICIAL_cfm_hein_latent_geodesic_leaveout/runs/27xfm3tg
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA A100-PCIE-40GB') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
/home/icb/alessandro.palma/miniconda3/envs/scCFM/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /lustre/groups/ml01/workspace/alessandro.palma/scCFM/experiments/2_OFFICIAL_cfm_hein_latent_geodesic_LEAVEOUT/checkpoints exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name      | Type      | Params
----------------------------------------
0 | net       | MLP       | 9.9 K 
1 | node      | NeuralODE | 9.9 K 
2 | criterion | MSELoss   | 0     
----------------------------------------
9.9 K     Trainable params
0         Non-trainable params
9.9 K     Total params
0.039     Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/home/icb/alessandro.palma/miniconda3/envs/scCFM/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 128 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/home/icb/alessandro.palma/miniconda3/envs/scCFM/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 128 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/home/icb/alessandro.palma/miniconda3/envs/scCFM/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:281: PossibleUserWarning: The number of training batches (9) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
  rank_zero_warn(
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                epoch ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:           train/loss █▆▅▃▃▃▂▃▂▃▂▃▂▃▂▂▂▂▂▁▂▂▂▁▂▂▁▁▂▂▂▂▂▁▁▁▁▁▁▁
wandb:  trainer/global_step ▁▁▁▂▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███
wandb:             val/loss █▆▄▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▂▁▁▁▁▂▂▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁
wandb: val/t1/1-Wasserstein █▇▆▆▆▅▅▄▄▅▃▄▄▄▄▃▂▂▅▃▃▄▃▂▂▄▃▂▁▂▁▂▂▁▂▂▂▂▁▃
wandb: val/t1/2-Wasserstein █▇▆▆▆▅▅▄▄▅▃▄▃▄▄▃▂▂▅▃▃▄▃▂▂▄▃▂▂▂▁▂▂▂▂▂▂▂▂▃
wandb:    val/t1/Linear_MMD ▆▅▂▃▄▄▄▂▂▃▃▂▃▅▇▂▁▂▅▃▃▇▄▄▂▅▃▃▁▄▂▃▄▂▃▃▂▃▁█
wandb:       val/t1/Mean_L1 █▇▂▃▄▆▄▂▄▅▄▄▅▅█▁▃▁▆▃▄▆▄▃▂▅▅▄▁▅▃▃▄▄▃▃▁▄▅▇
wandb:       val/t1/Mean_L2 █▆▂▃▄▆▅▂▄▅▃▄▅▅█▂▃▁▇▄▅▆▄▃▂▆▅▅▁▅▃▄▄▄▃▃▁▄▅█
wandb:      val/t1/Mean_MSE ▇▆▂▂▃▅▄▂▃▄▂▃▄▅█▁▂▁▆▃▄▆▃▂▂▅▄▅▁▄▂▃▃▃▃▂▁▃▄█
wandb:     val/t1/Median_L1 █▃▂▃▃▁▃▂▃▁▂▃▂▂▂▁▂▃▂▂▁▂▂▁▃▁▃▂▂▁▃▂▃▃▁▁▂▂▂▂
wandb:     val/t1/Median_L2 █▅▄▅▄▃▃▂▃▂▃▃▃▃▂▁▃▃▂▃▂▃▂▁▃▁▃▃▂▂▃▁▃▃▁▂▂▁▁▁
wandb:    val/t1/Median_MSE █▅▄▅▄▃▃▂▃▂▃▃▃▂▂▁▃▃▂▃▁▃▂▁▃▁▃▃▂▂▃▂▂▃▁▂▂▁▁▁
wandb:      val/t1/Poly_MMD ▇▅▃▃▅▅▅▃▂▄▄▂▃▆▇▂▂▃▆▄▄▇▄▄▃▆▄▄▁▅▂▄▅▃▄▄▃▄▁█
wandb:       val/t1/RBF_MMD ▆▇▃▃▆▆▄▃▃▃▄▂▃▆█▂▂▄▅▃▄█▅▄▃▆▄▄▁▅▂▃▆▃▄▄▃▄▁█
wandb: val/t2/1-Wasserstein █▃▃▃▃▁▃▂▃▁▃▃▂▂▂▁▃▃▂▂▁▃▂▁▃▁▃▂▃▁▄▂▃▃▁▂▂▂▂▂
wandb: val/t2/2-Wasserstein █▃▃▃▄▂▃▂▃▂▃▃▂▂▂▂▃▃▂▂▂▂▂▁▂▁▃▁▂▂▄▂▂▃▁▂▃▁▂▂
wandb:    val/t2/Linear_MMD █▃▃▃▃▂▃▂▄▂▃▃▃▂▃▁▃▄▂▃▂▃▃▂▄▂▃▃▃▂▅▂▃▂▂▂▃▂▂▂
wandb:       val/t2/Mean_L1 ▁▂▃▂▆▇▅▇▃▆▆▅▇▄▇▇▅▅▅▅▅▄▃▇▅▆▄▆▅▆▄▄█▆▇▅▅▆▆▇
wandb:       val/t2/Mean_L2 ▁▄▅▃▇▆▅▆▄▅▆▅▇▅█▇▄▆▅▅▄▇▄▆▇▇▄▇▄▅▅▅▇▆▇▅▆▅▆▆
wandb:      val/t2/Mean_MSE ▁▄▅▃▇▆▆▆▄▅▆▅▇▅█▇▅▆▆▅▅▇▄▇▇▇▅▇▅▆▅▅█▇▇▆▆▆▆▇
wandb:     val/t2/Median_L1 ▁▄▄▃▆▇▅▇▄▅▆▅▇▄▆▆▆▆▄█▆▅▃▇▅▇▆▅▅▅▇▆▇▇▇▆▆█▆█
wandb:     val/t2/Median_L2 ▁▃▄▃▆▇▆▇▄▇▇▆▇▄█▆▇▆▅▇▅▅▄▇▆▅▄▆▆▆▄▅█▆▇▅▆▇▅▇
wandb:    val/t2/Median_MSE ▁▃▄▂▆▇▆▇▃▆▆▆▇▅▇▇▅▅▅▆▅▅▃▇▆▆▄▆▅▆▅▅█▇▇▅▆▆▆▇
wandb:      val/t2/Poly_MMD █▄▃▃▄▂▄▃▄▂▄▄▄▂▃▁▃▄▃▃▂▃▃▂▄▂▃▃▃▂▅▂▃▂▂▂▃▃▂▃
wandb:       val/t2/RBF_MMD █▃▃▃▃▂▃▂▃▁▃▃▂▂▂▁▃▄▁▃▃▂▂▁▃▂▃▂▃▂▄▃▃▂▁▂▃▂▂▂
wandb: val/t3/1-Wasserstein ▁▄▄▄▆█▅█▄▆▆▅▇▄▆▆▆▆▅█▆▆▃▇▆▇▆▅▅▆▇▆▇█▇▆▇█▆█
wandb: val/t3/2-Wasserstein ▁▅▄▄▆▇▅▇▄▆▆▅▇▄▆▆▇▅▅█▅▅▃▆▅▆▆▅▆▅▆▅▇▆█▅▆▇▅█
wandb:    val/t3/Linear_MMD ██▆▇▅▄▆▄▄▃▄▃▃▃▄▃▃▄▃▃▃▃▂▂▂▃▂▃▃▁▂▁▁▂▁▂▂▃▁▂
wandb:       val/t3/Mean_L1 █▆▄▃▃▃▄▂▂▁▃▃▃▂▂▃▃▂▄▁▄▃▂▁▁▂▂▂▂▂▁▁▁▂▁▁▂▂▂▂
wandb:       val/t3/Mean_L2 █▆▄▄▃▄▆▃▃▂▂▄▃▄▃▃▃▃▄▄▄▄▂▃▃▄▂▃▃▁▂▂▂▂▂▃▂▃▂▄
wandb:      val/t3/Mean_MSE █▆▄▄▄▄▆▂▂▂▂▄▃▃▃▃▃▂▃▃▄▄▂▃▂▃▂▃▂▁▂▂▂▂▁▂▂▃▂▃
wandb:     val/t3/Median_L1 █▆▅▅▄▄▄▃▃▂▂▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▂▁▁▂▁▂▁▂▁
wandb:     val/t3/Median_L2 █▇▄▄▄▃▆▂▃▁▄▅▄▃▃▄▃▂▄▂▄▄▃▂▂▃▂▃▃▂▂▁▂▂▁▂▂▃▂▄
wandb:    val/t3/Median_MSE █▆▅▄▄▄▅▂▃▁▃▄▄▃▃▄▄▃▅▂▅▄▃▂▂▃▂▃▃▂▂▁▂▂▁▂▂▃▂▃
wandb:      val/t3/Poly_MMD █▇▆▇▅▄▆▄▄▃▄▃▃▃▄▃▃▄▃▃▃▃▂▂▂▃▂▃▃▁▂▁▁▂▁▂▂▃▁▃
wandb:       val/t3/RBF_MMD █▅▃▃▂▃▅▂▂▂▂▂▂▂▂▂▂▂▂▂▃▃▁▂▂▂▁▂▂▁▁▁▁▂▁▂▁▂▁▂
wandb: val/t4/1-Wasserstein █▆▅▄▃▄▄▂▂▂▂▂▃▃▂▂▂▂▂▂▂▂▂▂▂▂▁▂▁▂▁▂▁▁▂▁▂▁▂▁
wandb: val/t4/2-Wasserstein █▇▅▄▂▃▅▂▂▂▂▂▄▄▁▃▁▃▂▁▂▁▂▄▁▁▁▂▁▂▁▂▂▁▄▁▁▁▃▂
wandb:    val/t4/Linear_MMD █▇▆▅▃▄▆▃▃▂▂▃▅▅▂▄▂▄▂▂▂▂▂▅▂▁▁▃▂▃▁▃▃▁▅▁▂▂▄▂
wandb:       val/t4/Mean_L1 █▅▄▃▃▃▂▂▂▃▂▂▂▁▂▂▂▂▂▁▁▂▁▂▂▂▁▂▂▁▁▂▁▁▁▁▂▁▁▁
wandb:       val/t4/Mean_L2 ██▆▆▃▄▆▃▃▃▃▃▄▄▂▃▁▂▂▂▃▂▃▄▂▁▁▃▂▄▂▃▂▃▅▂▃▂▃▂
wandb:      val/t4/Mean_MSE ██▆▅▃▄▅▃▄▃▄▃▄▅▂▃▂▃▃▃▄▂▄▄▃▁▂▃▂▃▂▃▃▃▆▂▃▂▃▂
wandb:     val/t4/Median_L1 █▅▂▃▅▄▄▂▃▄▃▃▂▁▃▂▂▄▂▂▄▅▁▄▃▃▂▄▄▂▂▆▄▁▁▅▄▁▄▂
wandb:     val/t4/Median_L2 █▄▂▂▄▃▃▁▂▃▂▂▁▁▂▂▂▃▂▁▃▃▁▃▂▂▁▃▃▂▂▆▃▁▁▃▃▁▃▂
wandb:    val/t4/Median_MSE █▄▃▃▃▃▂▂▂▃▂▂▂▁▂▂▂▂▂▁▁▂▁▂▂▂▂▂▂▁▂▂▁▁▁▂▂▁▁▁
wandb:      val/t4/Poly_MMD █▇▆▆▃▃▆▄▃▂▃▂▅▅▂▃▁▄▂▁▁▂▂▄▁▁▁▃▂▄▁▃▂▂▄▁▂▂▄▂
wandb:       val/t4/RBF_MMD ██▆▄▂▃▅▂▃▂▃▂▃▄▁▂▁▂▂▂▃▂▃▃▂▁▁▂▂▂▂▂▂▂▅▂▂▂▂▂
wandb: val/t5/1-Wasserstein █▅▃▃▅▃▄▂▃▄▃▃▁▂▃▂▂▄▂▂▄▅▁▄▂▃▂▄▄▂▂▇▄▂▁▅▄▁▄▂
wandb: val/t5/2-Wasserstein ▄▃▁▁▃▂▃▄▅▅▂▂▂▁▅▃▁▃▂▂▄▅▂▂▃▅▂▄▄▁▁█▂▁▁▇▃▁▂▂
wandb:    val/t5/Linear_MMD ▅▄▂▂▄▃▄▅▆▆▃▃▂▁▆▄▂▄▂▃▅▆▂▃▄▆▃▅▅▁▂█▃▂▁▇▅▁▃▂
wandb:       val/t5/Mean_L1 █▅▅▃▇▃▅▃▂▅▁▂▃▂▃▄▃▄▄▄▅▅▃▃▂▂▄▂▂▄▃▅▂▃▃▂▅▂▃▃
wandb:       val/t5/Mean_L2 █▄▄▂▇▂▄▂▁▄▁▁▂▁▂▃▃▃▃▃▄▄▂▂▁▂▃▂▁▃▂▄▁▂▂▁▄▁▂▂
wandb:      val/t5/Mean_MSE █▄▄▃▃▂▂▁▂▃▁▂▂▁▂▂▂▂▂▃▂▂▁▂▂▂▂▁▁▂▂▂▁▂▂▂▂▂▁▂
wandb:     val/t5/Median_L1 █▅▆▅▅▃▄▃▂▆▂▁▄▂▆▃▃▂▂▅▄▃▃▄▂▂▄▃▂▃▄▅▃▂▄▃▆▂▄▂
wandb:     val/t5/Median_L2 █▄▅▄▄▂▃▂▁▅▂▁▃▁▅▂▂▂▂▄▃▂▂▃▁▁▃▂▂▂▃▄▂▁▃▂▅▁▃▂
wandb:    val/t5/Median_MSE ▇▆▆▄█▃▇▃▂▅▁▂▃▂▃▃▄▅▅▄▅▆▄▃▂▂▄▂▂▄▃▇▂▃▃▂▅▂▄▃
wandb:      val/t5/Poly_MMD ▅▄▂▁▄▃▄▄▅▅▃▃▂▁▅▄▁▄▃▃▅▆▂▃▄▅▃▄▅▁▂█▄▂▁▇▄▁▂▃
wandb:       val/t5/RBF_MMD █▄▄▃▃▂▂▁▂▃▁▁▂▁▂▂▂▂▂▃▂▂▂▂▂▂▂▁▁▂▂▂▁▂▂▂▂▂▁▂
wandb: val/t6/1-Wasserstein █▅▅▄▆▃▅▂▁▆▂▁▃▂▆▃▃▂▂▅▄▃▄▃▂▁▄▃▂▃▃▅▂▂▂▂▅▂▃▂
wandb: val/t6/2-Wasserstein █▅▄▄▄▃▃▂▂▃▂▂▂▂▃▂▂▂▂▂▁▂▁▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁
wandb:    val/t6/Linear_MMD █▅▄▄▄▃▃▂▂▃▂▂▂▂▃▂▂▂▂▂▁▂▁▂▂▂▁▂▁▁▁▁▂▁▁▁▁▁▁▁
wandb:       val/t6/Mean_L1 █▅▃▂▄▃▄▂▂▃▂▂▃▁▄▂▁▂▂▃▄▃▁▂▁▂▂▃▁▁▂▃▂▁▂▂▃▁▂▂
wandb:       val/t6/Mean_L2 █▄▃▂▃▂▃▂▂▂▂▂▃▁▃▁▂▂▁▃▂▂▁▂▂▂▂▂▂▁▃▃▂▂▂▂▃▂▁▂
wandb:      val/t6/Mean_MSE █▅▃▃▄▃▅▂▂▂▂▂▃▂▃▂▂▃▂▂▂▄▁▃▂▂▁▂▂▂▂▃▃▂▂▂▂▁▂▃
wandb:    val/t6/Median_MSE █▆▃▂▄▃▄▁▂▃▂▂▃▁▄▂▂▂▂▂▃▃▁▂▁▁▂▂▂▁▂▃▂▁▁▂▂▁▁▃
wandb:      val/t6/Poly_MMD █▃▂▂▃▂▄▂▂▂▂▂▃▂▂▂▂▃▂▁▁▃▁▃▂▂▂▂▂▂▂▂▃▂▂▁▂▂▂▂
wandb:       val/t6/RBF_MMD █▅▃▃▄▃▅▂▁▂▂▂▃▂▃▂▁▃▂▁▂▃▁▃▁▂▁▃▁▂▁▂▃▂▂▂▂▁▂▃
wandb: 
wandb: Run summary:
wandb:                epoch 1471
wandb:           train/loss 0.0542
wandb:  trainer/global_step 13247
wandb:             val/loss 0.0555
wandb: val/t1/1-Wasserstein 0.66895
wandb: val/t1/2-Wasserstein 0.69535
wandb:    val/t1/Linear_MMD 0.00218
wandb:       val/t1/Mean_L1 0.05299
wandb:       val/t1/Mean_L2 0.08008
wandb:      val/t1/Mean_MSE 0.00641
wandb:     val/t1/Median_L1 0.04237
wandb:     val/t1/Median_L2 1.2424
wandb:    val/t1/Median_MSE 1.19725
wandb:      val/t1/Poly_MMD 0.04671
wandb:       val/t1/RBF_MMD 0.03316
wandb: val/t2/1-Wasserstein 0.20585
wandb: val/t2/2-Wasserstein 0.1626
wandb:    val/t2/Linear_MMD 0.05541
wandb:       val/t2/Mean_L1 0.02097
wandb:       val/t2/Mean_L2 1.06623
wandb:      val/t2/Mean_MSE 1.01302
wandb:     val/t2/Median_L1 0.03057
wandb:     val/t2/Median_L2 0.11514
wandb:    val/t2/Median_MSE 0.1448
wandb:      val/t2/Poly_MMD 0.23538
wandb:       val/t2/RBF_MMD 0.19228
wandb: val/t3/1-Wasserstein 0.17484
wandb: val/t3/2-Wasserstein 0.13645
wandb:    val/t3/Linear_MMD 0.78794
wandb:       val/t3/Mean_L1 0.0022
wandb:       val/t3/Mean_L2 0.03255
wandb:      val/t3/Mean_MSE 0.0391
wandb:     val/t3/Median_L1 0.80089
wandb:     val/t3/Median_L2 0.04117
wandb:    val/t3/Median_MSE 0.04694
wandb:      val/t3/Poly_MMD 0.82538
wandb:       val/t3/RBF_MMD 0.00153
wandb: val/t4/1-Wasserstein 0.84495
wandb: val/t4/2-Wasserstein 0.00169
wandb:    val/t4/Linear_MMD 0.04111
wandb:       val/t4/Mean_L1 0.65107
wandb:       val/t4/Mean_L2 0.03849
wandb:      val/t4/Mean_MSE 0.04827
wandb:     val/t4/Median_L1 0.03883
wandb:     val/t4/Median_L2 0.00151
wandb:    val/t4/Median_MSE 0.71369
wandb:      val/t4/Poly_MMD 0.03364
wandb:       val/t4/RBF_MMD 0.00233
wandb: val/t5/1-Wasserstein 0.02823
wandb: val/t5/2-Wasserstein 0.00429
wandb:    val/t5/Linear_MMD 0.06548
wandb:       val/t5/Mean_L1 0.0411
wandb:       val/t5/Mean_L2 0.00169
wandb:      val/t5/Mean_MSE 0.59004
wandb:     val/t5/Median_L1 0.06075
wandb:     val/t5/Median_L2 0.00369
wandb:    val/t5/Median_MSE 0.0289
wandb:      val/t5/Poly_MMD 0.04632
wandb:       val/t5/RBF_MMD 0.53667
wandb: val/t6/1-Wasserstein 0.04614
wandb: val/t6/2-Wasserstein 0.80797
wandb:    val/t6/Linear_MMD 0.85401
wandb:       val/t6/Mean_L1 0.10168
wandb:       val/t6/Mean_L2 0.01499
wandb:      val/t6/Mean_MSE 0.06203
wandb:    val/t6/Median_MSE 0.07912
wandb:      val/t6/Poly_MMD 0.01028
wandb:       val/t6/RBF_MMD 0.07964
wandb: 
wandb: 🚀 View run lunar-lion-3 at: https://wandb.ai/allepalma/2_OFFICIAL_cfm_hein_latent_geodesic_leaveout/runs/27xfm3tg
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: /home/icb/alessandro.palma/environment/scCFM/project_dir/experiments/2_OFFICIAL_cfm_hein_latent_geodesic_LEAVEOUT/wandb/run-20230923_153602-27xfm3tg/logs
