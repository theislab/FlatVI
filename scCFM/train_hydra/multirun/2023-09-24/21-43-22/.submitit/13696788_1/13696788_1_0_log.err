WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
I0000 00:00:1695584643.428086 3158264 tfrt_cpu_pjrt_client.cc:349] TfrtCpuClient created.
No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
/home/icb/alessandro.palma/miniconda3/envs/scCFM/lib/python3.10/site-packages/scvi/_settings.py:63: UserWarning: Since v1.0.0, scvi-tools no longer uses a random seed by default. Run `scvi.settings.seed = 0` to reproduce results from previous versions.
  self.seed = seed
/home/icb/alessandro.palma/miniconda3/envs/scCFM/lib/python3.10/site-packages/scvi/_settings.py:70: UserWarning: Setting `dl_pin_memory_gpu_training` is deprecated in v1.0 and will be removed in v1.1. Please pass in `pin_memory` to the data loaders instead.
  self.dl_pin_memory_gpu_training = (
wandb: Currently logged in as: allepalma. Use `wandb login --relogin` to force relogin
wandb: wandb version 0.15.11 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.15.10
wandb: Run data is saved locally in /home/icb/alessandro.palma/environment/scCFM/project_dir/experiments/2_OFFICIAL_cfm_hein_latent_geodesic_LEAVEOUT/wandb/run-20230924_214412-pgh7adm5
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run worldly-dream-4
wandb: ⭐️ View project at https://wandb.ai/allepalma/2_OFFICIAL_cfm_hein_latent_geodesic_leaveout
wandb: 🚀 View run at https://wandb.ai/allepalma/2_OFFICIAL_cfm_hein_latent_geodesic_leaveout/runs/pgh7adm5
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
/home/icb/alessandro.palma/miniconda3/envs/scCFM/lib/python3.10/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /lustre/groups/ml01/workspace/alessandro.palma/scCFM/experiments/2_OFFICIAL_cfm_hein_latent_geodesic_LEAVEOUT/checkpoints exists and is not empty.
  rank_zero_warn(f"Checkpoint directory {dirpath} exists and is not empty.")
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name      | Type      | Params
----------------------------------------
0 | net       | MLP       | 9.9 K 
1 | node      | NeuralODE | 9.9 K 
2 | criterion | MSELoss   | 0     
----------------------------------------
9.9 K     Trainable params
0         Non-trainable params
9.9 K     Total params
0.039     Total estimated model params size (MB)
SLURM auto-requeueing enabled. Setting signal handlers.
/home/icb/alessandro.palma/miniconda3/envs/scCFM/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 112 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/home/icb/alessandro.palma/miniconda3/envs/scCFM/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:212: UserWarning: You called `self.log('leaveout_timepoint', ...)` in your `validation_step` but the value needs to be floating point. Converting it to torch.float32.
  warning_cache.warn(
/home/icb/alessandro.palma/miniconda3/envs/scCFM/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 112 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/home/icb/alessandro.palma/miniconda3/envs/scCFM/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:281: PossibleUserWarning: The number of training batches (9) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.
  rank_zero_warn(
wandb: Waiting for W&B process to finish... (success).
wandb: 
wandb: Run history:
wandb:                epoch ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:   leaveout_timepoint ▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁
wandb:           train/loss █▆▅▄▃▅▃▃▃▃▂▃▂▂▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▁▂▂▂
wandb:  trainer/global_step ▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇███
wandb:             val/loss █▇▅▄▃▃▃▃▂▂▃▂▂▂▂▁▂▂▂▁▁▂▁▂▂▂▁▂▁▂▂▁▁▁▁▁▁▁▁▁
wandb: val/t1/1-Wasserstein █▇▅▆▅▄▅▂▄▃▂▂▂▃▃▃▄▂▂▂▂▂▂▂▃▁▃▂▃▂▁▃▃▂▂▂▁▂▂▂
wandb: val/t1/2-Wasserstein █▆▆▆▆▄▅▃▄▃▂▂▂▂▃▃▄▂▂▂▂▂▂▂▃▁▃▂▃▂▁▃▃▂▂▂▁▂▂▂
wandb:    val/t1/Linear_MMD █▅▂▄▂▂▅▁▂▃▂▂▂▂▂▄▇▁▃▂▃▃▃▂▃▁▄▂▄▁▂▄▃▂▄▃▂▄▅▃
wandb:       val/t1/Mean_L1 █▆▂▅▄▃▄▁▂▁▁▂▂▃▃▃▇▂▂▃▃▁▄▁▂▂▃▂▄▁▃▃▃▂▂▃▃▂▄▂
wandb:       val/t1/Mean_L2 █▆▃▇▅▄▇▁▂▁▁▂▂▃▃▄▇▁▃▃▄▂▄▁▂▁▃▂▅▁▃▃▃▂▂▃▃▃▅▁
wandb:      val/t1/Mean_MSE █▅▂▆▄▃▆▁▂▁▁▂▂▃▂▃▇▁▃▂▃▂▃▁▁▁▂▂▄▁▃▂▃▂▂▂▂▂▄▁
wandb:     val/t1/Median_L1 █▄▃▃▂▁▃▂▂▃▂▂▂▂▁▂▃▂▃▂▂▁▃▂▃▂▁▃▂▁▂▂▂▂▂▂▂▂▁▂
wandb:     val/t1/Median_L2 █▅▅▅▄▂▄▃▃▃▃▃▃▂▂▃▃▂▃▃▂▂▃▂▃▂▂▃▂▂▂▂▂▂▂▂▂▁▁▂
wandb:    val/t1/Median_MSE █▅▅▅▃▂▄▃▃▃▃▃▃▂▂▃▃▂▃▃▂▂▃▂▃▂▂▃▂▁▂▂▂▂▂▂▂▁▁▁
wandb:      val/t1/Poly_MMD █▆▃▅▃▂▆▁▃▄▃▃▂▂▃▅▇▂▄▃▄▄▄▃▄▁▅▃▅▂▃▅▄▃▅▄▃▅▆▄
wandb:       val/t1/RBF_MMD █▆▃▄▃▂▅▁▃▄▃▃▂▂▄▅█▂▄▂▂▄▄▃▄▁▅▃▅▂▂▄▄▃▅▄▄▅▆▄
wandb: val/t2/1-Wasserstein █▄▃▃▂▁▃▂▂▃▃▂▂▂▁▃▃▂▃▂▂▁▃▂▃▂▁▃▂▂▂▂▃▂▂▂▃▂▁▂
wandb: val/t2/2-Wasserstein █▄▄▄▂▂▃▂▂▃▃▃▂▂▁▃▄▃▃▂▂▁▃▂▃▂▁▂▂▁▂▁▂▂▂▂▃▂▁▂
wandb:    val/t2/Linear_MMD █▄▄▂▂▁▂▂▃▃▃▂▂▂▁▃▃▂▂▁▂▁▃▂▂▁▁▃▃▁▂▂▃▃▂▁▂▁▁▁
wandb:       val/t2/Mean_L1 ▁▂▃▂▃▃▃▃▂▇▅▆▅▅▇▅▄▄▇▆▆▅▅▆▄▄▅▄▄▄▄▆▅█▃▆▆▆▄▇
wandb:       val/t2/Mean_L2 ▁▁▄▂▃▂▄▄▄▆▅▆▅▅▅▅▄▄▇▇█▅▆▆▅▅▆▅▅▅▄▇▅▇▃▇▇▅▆▆
wandb:      val/t2/Mean_MSE ▁▁▄▂▃▃▄▄▄▆▅▆▆▅▆▆▄▅▇▇█▅▆▇▅▆▆▆▆▅▅▇▅█▄▇▇▆▆▇
wandb:     val/t2/Median_L1 ▁▂▃▂▃▃▂▄▂▇▅▅▅▆█▄▄▄▆▇▆▅▇█▅▄▅▅▄▅▆▇▆█▄▆▇▆▆▆
wandb:     val/t2/Median_L2 ▁▂▃▁▃▃▂▃▂▆▅▅▅▄▅▆▄▅▅▆▆▅▅▅▄▄▄▄▃▄▅▆▆█▃▅▄▆▅▇
wandb:    val/t2/Median_MSE ▁▂▃▂▃▃▃▄▃▇▅▆▅▅▇▆▄▅▇▆▇▅▅▆▅▄▆▅▄▄▅▇▅█▃▆▆▆▅▇
wandb:      val/t2/Poly_MMD █▅▄▂▂▁▂▂▃▄▃▂▂▂▁▃▃▂▂▁▂▁▃▂▃▁▁▃▃▁▃▂▃▃▃▁▃▁▂▁
wandb:       val/t2/RBF_MMD █▅▅▂▂▁▂▂▃▅▃▃▂▂▁▄▃▃▂▂▂▂▄▃▃▂▂▃▂▂▃▂▄▄▃▂▃▃▃▃
wandb: val/t3/1-Wasserstein ▁▂▃▂▃▄▃▅▃▇▅▆▅▆█▅▄▄▇▇▆▅▇█▅▄▅▆▄▅▆▇▆█▅▆▇▆▆▇
wandb: val/t3/2-Wasserstein ▁▁▂▁▂▃▁▄▁▆▄▄▄▅▆▄▃▄▄▆▅▅▇▅▄▄▄▄▃▄▆▆▆█▃▅▄▅▆▅
wandb:    val/t3/Linear_MMD ▇█▇▆▄▃▅▆▃▄▂▃▃▃▃▂▃▃▃▃▄▂▂▂▁▂▂▁▃▃▃▁▂▃▂▂▁▂▃▂
wandb:       val/t3/Mean_L1 ▆█▅▅▃▁▄▄▂▂▂▂▂▂▂▁▂▂▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▁▁▂▂▃▃▃
wandb:       val/t3/Mean_L2 ▇█▆▆▅▁▅▅▃▄▁▂▂▂▃▁▂▂▃▃▄▂▂▂▂▃▁▁▂▁▂▂▃▂▁▂▃▄▃▂
wandb:      val/t3/Mean_MSE ██▆▆▅▂▅▅▃▄▁▂▂▂▃▁▂▂▃▄▄▂▂▂▂▂▁▁▂▁▃▂▃▃▁▂▂▄▃▂
wandb:     val/t3/Median_L1 █▇▅▅▄▄▃▃▃▃▃▃▂▂▃▂▂▃▂▂▃▂▂▃▁▂▂▂▁▁▁▂▂▂▂▁▁▁▁▁
wandb:     val/t3/Median_L2 ▇█▆▆▃▂▅▅▃▃▃▄▂▃▃▁▃▂▄▄▄▃▄▄▃▃▂▃▂▃▄▃▃▂▁▂▃▅▄▄
wandb:    val/t3/Median_MSE ▇█▆▆▄▂▅▅▃▃▃▃▂▃▃▁▃▂▄▄▄▃▄▃▂▃▂▃▂▃▄▃▃▂▁▂▃▄▄▄
wandb:      val/t3/Poly_MMD ██▇▆▅▃▅▆▄▄▂▃▂▂▃▂▃▄▃▃▅▂▂▂▁▂▃▁▃▃▄▁▂▂▂▂▁▂▄▂
wandb:       val/t3/RBF_MMD ▇█▅▅▄▁▄▄▂▃▁▂▁▁▂▁▂▂▂▃▃▂▂▂▂▂▁▁▂▁▂▁▂▂▁▂▂▃▂▂
wandb: val/t4/1-Wasserstein █▇▄▄▃▃▃▃▃▃▂▃▂▂▃▂▂▂▂▂▃▂▂▂▁▂▂▂▂▁▁▂▂▂▂▁▂▁▁▂
wandb: val/t4/2-Wasserstein █▄▃▃▁▂▁▁▂▃▂▂▂▁▂▁▁▂▁▁▃▁▁▂▁▂▂▂▁▁▁▁▁▁▂▁▁▁▁▂
wandb:    val/t4/Linear_MMD █▆▄▄▂▂▂▁▃▄▂▂▂▂▃▂▂▃▂▂▄▁▂▃▂▃▂▃▂▁▂▂▂▂▃▁▁▁▁▂
wandb:       val/t4/Mean_L1 █▆▅▄▃▄▃▃▂▂▂▂▂▂▂▂▂▂▂▃▂▃▂▂▁▂▂▂▁▁▂▂▂▂▁▁▂▂▂▂
wandb:       val/t4/Mean_L2 █▆▅▅▃▃▂▂▃▅▃▃▂▂▂▃▂▃▂▂▄▂▂▃▂▃▂▃▂▂▂▂▁▂▃▂▁▁▁▂
wandb:      val/t4/Mean_MSE █▆▅▄▃▂▂▂▃▅▃▃▂▂▂▂▂▃▂▁▄▁▂▃▂▃▂▂▂▂▂▂▁▂▂▂▂▁▁▂
wandb:     val/t4/Median_L1 █▇▆▅▅▇▆▅▄▃▂▁▁▃▂▄▃▂▇▆▂█▃▃▃▃▃▄▁▃▄▃▃▄▃▂▂▁▅▂
wandb:     val/t4/Median_L2 █▆▅▄▄▆▆▄▂▂▂▁▁▂▁▃▂▁▆▅▁▇▂▂▂▂▂▂▁▂▃▂▂▃▂▂▂▁▄▁
wandb:    val/t4/Median_MSE █▆▅▄▃▄▃▂▂▂▂▂▂▂▂▂▂▂▃▃▂▃▂▂▁▂▂▂▁▁▂▂▂▂▁▁▂▁▂▂
wandb:      val/t4/Poly_MMD █▆▅▅▂▃▂▂▃▅▃▃▃▃▄▂▂▃▂▂▄▂▂▄▂▃▃▃▃▂▂▂▂▂▃▂▁▂▁▃
wandb:       val/t4/RBF_MMD █▅▄▃▂▂▂▂▂▄▂▂▂▁▂▂▂▂▁▁▃▁▁▂▁▂▂▂▁▁▂▁▁▁▂▁▁▁▁▁
wandb: val/t5/1-Wasserstein ▇▇▆▆▄▇▇▅▄▃▃▁▁▂▂▃▃▂█▆▂█▃▄▃▃▃▄▂▃▄▃▃▄▃▂▃▂▅▂
wandb: val/t5/2-Wasserstein ▃▂▃▂▃▄▄▂▂▂▁▁▁▁▁▂▁▁▆▅▁█▁▃▂▃▄▂▁▁▂▂▃▄▁▃▁▁▂▂
wandb:    val/t5/Linear_MMD ▄▄▄▃▄▅▅▃▃▃▁▂▂▂▁▂▂▁▇▆▁█▁▄▂▄▅▃▁▂▂▂▄▅▁▄▂▁▃▂
wandb:       val/t5/Mean_L1 █▃▄▂▃▂▂▃▅▃▃▃▃▄▄▄▄▃▂▃▄▂▄▆▅▄▃▃▃▃▂▂▁▄▃▁▄▃▄▄
wandb:       val/t5/Mean_L2 █▂▃▁▂▂▁▂▄▂▂▂▂▃▃▃▃▂▂▂▂▁▃▅▄▃▂▂▂▂▂▁▁▃▂▁▃▂▃▃
wandb:      val/t5/Mean_MSE █▆▄▄▃▃▂▂▃▃▁▂▃▃▃▃▂▃▂▂▂▃▃▃▃▃▂▂▁▁▁▁▁▂▂▂▂▂▂▂
wandb:     val/t5/Median_L1 █▅▆▅▃▄▄▂▅▃▃▂▃▅▄▄▂▃▃▂▂▁▅▄▅▃▃▁▂▃▁▂▁▅▃▁▅▂▄▃
wandb:     val/t5/Median_L2 █▄▅▄▂▃▃▁▅▂▂▂▂▅▄▃▂▃▂▂▁▁▄▃▄▂▂▁▁▂▁▂▁▄▂▁▄▁▃▂
wandb:    val/t5/Median_MSE █▄▅▂▃▂▂▃▇▄▄▄▄▄▅▅▄▃▃▃▅▂▄█▇▆▃▄▃▃▃▂▁▃▃▁▅▄▅▅
wandb:      val/t5/Poly_MMD ▅▄▅▃▄▅▆▄▃▄▁▂▂▂▂▃▂▁█▆▁█▁▅▃▅▅▃▁▂▂▂▄▅▂▄▂▂▃▂
wandb:       val/t5/RBF_MMD █▆▄▄▂▃▂▂▃▂▁▂▂▃▃▃▂▂▂▂▂▃▂▃▃▃▂▂▁▁▁▁▁▂▁▂▂▂▂▂
wandb: val/t6/1-Wasserstein █▅▅▅▂▄▄▂▆▃▃▃▃▅▅▄▃▄▃▂▂▂▅▅▅▄▃▂▂▃▁▂▁▄▂▁▄▂▄▃
wandb: val/t6/2-Wasserstein █▆▅▄▃▃▃▃▂▃▂▃▂▂▂▂▂▂▂▃▃▂▂▃▂▂▂▂▂▁▁▂▂▂▁▂▂▁▂▂
wandb:    val/t6/Linear_MMD █▆▅▄▃▃▃▃▂▃▂▂▂▂▂▂▂▂▂▃▃▂▂▃▂▂▂▂▂▁▁▂▂▂▁▂▂▁▂▂
wandb:       val/t6/Mean_L1 █▆▅▄▃▂▄▂▃▃▁▂▁▃▃▂▂▁▄▃▂▃▃▃▂▂▂▂▁▁▂▂▂▄▁▂▃▁▃▂
wandb:       val/t6/Mean_L2 █▅▄▃▂▁▂▂▂▄▂▂▁▂▂▂▂▁▃▃▂▃▃▃▂▁▂▂▂▁▂▂▂▄▁▂▃▁▂▂
wandb:      val/t6/Mean_MSE █▆▄▄▂▂▃▂▃▄▂▂▂▂▃▃▃▂▄▃▃▃▃▃▃▂▂▃▂▁▂▂▂▃▂▂▂▃▃▃
wandb:    val/t6/Median_MSE █▆▅▄▂▂▃▂▂▄▂▂▂▃▃▃▃▂▃▃▂▃▃▄▂▂▂▂▁▂▂▂▃▄▁▂▂▂▃▂
wandb:      val/t6/Poly_MMD █▄▃▂▂▁▂▂▁▃▂▂▁▂▂▂▂▁▃▂▃▂▂▂▂▂▂▂▂▁▂▂▂▃▁▂▂▂▂▂
wandb:       val/t6/RBF_MMD █▅▄▃▂▂▃▂▂▃▂▂▁▂▂▃▃▂▃▃▃▂▂▃▂▂▂▂▂▁▂▂▂▃▂▂▂▂▃▂
wandb: 
wandb: Run summary:
wandb:                epoch 1026
wandb:   leaveout_timepoint 2.0
wandb:           train/loss 0.05624
wandb:  trainer/global_step 9242
wandb:             val/loss 0.05574
wandb: val/t1/1-Wasserstein 0.67494
wandb: val/t1/2-Wasserstein 0.70058
wandb:    val/t1/Linear_MMD 0.00098
wandb:       val/t1/Mean_L1 0.03234
wandb:       val/t1/Mean_L2 0.03849
wandb:      val/t1/Mean_MSE 0.00148
wandb:     val/t1/Median_L1 0.03654
wandb:     val/t1/Median_L2 1.21257
wandb:    val/t1/Median_MSE 1.17483
wandb:      val/t1/Poly_MMD 0.03126
wandb:       val/t1/RBF_MMD 0.02722
wandb: val/t2/1-Wasserstein 0.19117
wandb: val/t2/2-Wasserstein 0.14583
wandb:    val/t2/Linear_MMD 0.0522
wandb:       val/t2/Mean_L1 0.03082
wandb:       val/t2/Mean_L2 1.15516
wandb:      val/t2/Mean_MSE 1.0893
wandb:     val/t2/Median_L1 0.04241
wandb:     val/t2/Median_L2 0.14465
wandb:    val/t2/Median_MSE 0.17554
wandb:      val/t2/Poly_MMD 0.22848
wandb:       val/t2/RBF_MMD 0.1813
wandb: val/t3/1-Wasserstein 0.20594
wandb: val/t3/2-Wasserstein 0.16381
wandb:    val/t3/Linear_MMD 0.80348
wandb:       val/t3/Mean_L1 0.00633
wandb:       val/t3/Mean_L2 0.03788
wandb:      val/t3/Mean_MSE 0.04728
wandb:     val/t3/Median_L1 0.80473
wandb:     val/t3/Median_L2 0.0586
wandb:    val/t3/Median_MSE 0.07959
wandb:      val/t3/Poly_MMD 0.84551
wandb:       val/t3/RBF_MMD 0.00224
wandb: val/t4/1-Wasserstein 0.84917
wandb: val/t4/2-Wasserstein 0.00274
wandb:    val/t4/Linear_MMD 0.05238
wandb:       val/t4/Mean_L1 0.67609
wandb:       val/t4/Mean_L2 0.04926
wandb:      val/t4/Mean_MSE 0.05868
wandb:     val/t4/Median_L1 0.04745
wandb:     val/t4/Median_L2 0.00225
wandb:    val/t4/Median_MSE 0.7375
wandb:      val/t4/Poly_MMD 0.03944
wandb:       val/t4/RBF_MMD 0.00344
wandb: val/t5/1-Wasserstein 0.0422
wandb: val/t5/2-Wasserstein 0.00511
wandb:    val/t5/Linear_MMD 0.07151
wandb:       val/t5/Mean_L1 0.03524
wandb:       val/t5/Mean_L2 0.00124
wandb:      val/t5/Mean_MSE 0.58774
wandb:     val/t5/Median_L1 0.0641
wandb:     val/t5/Median_L2 0.00411
wandb:    val/t5/Median_MSE 0.02808
wandb:      val/t5/Poly_MMD 0.04973
wandb:       val/t5/RBF_MMD 0.53753
wandb: val/t6/1-Wasserstein 0.04598
wandb: val/t6/2-Wasserstein 0.82298
wandb:    val/t6/Linear_MMD 0.86975
wandb:       val/t6/Mean_L1 0.10668
wandb:       val/t6/Mean_L2 0.01644
wandb:      val/t6/Mean_MSE 0.06647
wandb:    val/t6/Median_MSE 0.083
wandb:      val/t6/Poly_MMD 0.01097
wandb:       val/t6/RBF_MMD 0.0829
wandb: 
wandb: 🚀 View run worldly-dream-4 at: https://wandb.ai/allepalma/2_OFFICIAL_cfm_hein_latent_geodesic_leaveout/runs/pgh7adm5
wandb: Synced 6 W&B file(s), 0 media file(s), 1 artifact file(s) and 0 other file(s)
wandb: Find logs at: /home/icb/alessandro.palma/environment/scCFM/project_dir/experiments/2_OFFICIAL_cfm_hein_latent_geodesic_LEAVEOUT/wandb/run-20230924_214412-pgh7adm5/logs
