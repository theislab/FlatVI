seml:
  executable: ../scCFM/train_vae.py
  name: sweep_vae_eb_lib
  output_dir: /nfs/homedirs/pala/scCFM/project_dir/experiments/sweep_vae_eb/logs
  conda_environment: scCFM
  project_root_dir: ../../../scCFM

slurm:
  max_simultaneous_jobs: 5
  experiments_per_job: 1
  sbatch_options_template: GPU
  sbatch_options:
    gres: gpu:1       # num GPUs
    mem: 90G          # memory
    cpus-per-task: 6  # num cores
    time: 2-00:00     # max time, D-HH:MM

########## HYPERPARAMETER TUNING ##########

fixed: 
  # General hparameters 
  training.task_name: sweep_vae_eb_lib
  training.seed: 42

  # Datamodule hyperparameters 
  datamodule.path: /nfs/homedirs/pala/scCFM/project_dir/data/eb/processed/eb_phate.h5ad
  datamodule.x_layer: X_norm
  datamodule.cond_key: experimental_time
  datamodule.use_pca: False
  datamodule.n_dimensions: Null
  datamodule.train_val_test_split: [0.80, 0.2]
  datamodule.batch_size: 256
  datamodule.num_workers: 2

  # Model
  model.n_epochs: 200
  model.kl_weight: Null
  model.likelihood: nb
  model.dropout: False
  model.dropout_p: False
  model.train_vae: True

  # Callbacks 
  model_checkpoint.filename: "epoch_{epoch:04d}"
  model_checkpoint.monitor: val/loss
  model_checkpoint.mode: min
  model_checkpoint.save_last: False
  model_checkpoint.auto_insert_metric_name: False

  early_stopping.monitor: val/loss
  early_stopping.patience: 20
  early_stopping.mode: min
  early_stopping.min_delta: 0. # minimum change in the monitored quantity to qualify as an improvement
  early_stopping.verbose: False # verbosity mode
  early_stopping.strict: True # whether to crash the training if monitor is not found in the validation metrics
  early_stopping.check_finite: True # when set True, stops training when the monitor becomes NaN or infinite
  early_stopping.stopping_threshold: null # stop training immediately once the monitored quantity reaches this threshold
  early_stopping.divergence_threshold: null # stop training as soon as the monitored quantity becomes worse than this threshold
  early_stopping.check_on_train_epoch_end: null # whether to run early stopping at the end of the training epoch

  # Logger 
  logger.offline: False
  logger.id: null # pass correct id to resume experiment!
  logger.project: scCFM_vae_sweep_lib
  logger.log_model: True # upload lightning ckpts
  logger.prefix: "" # a string to put at the beginning of metric keys
  logger.group: ""
  logger.tags: []
  logger.job_type: ""

  # Trainer
  trainer.max_epochs: 200
  trainer.accelerator: gpu
  trainer.devices: 1
  trainer.log_every_n_steps: 10

random:
  samples: 12
  seed: 42

  model.hidden_dims: 
    type: choice
    options:
      - [256, 128, 64]
      - [512, 256, 64]
      - [256, 128, 32]

  model.batch_norm: 
    type: choice 
    options:
      - True
      - False 
    
  model.kl_warmup_fraction: 
    type: choice
    options:
      - 0.5
      - 1
      - 2